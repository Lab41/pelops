{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/fs4/home/dgrossman/deep-learning-models\n"
     ]
    }
   ],
   "source": [
    "cd 'deep-learning-models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "import scipy.spatial.distance\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    data = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(data)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def get_base_model():\n",
    "#    base_model = ResNet50(weights='imagenet',include_top=False)\n",
    "#    return base_model\n",
    "\n",
    "def get_models():\n",
    "    # include_top needs to be True for this to work\n",
    "    base_model = ResNet50(weights='imagenet',include_top=True)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('flatten_1').output)\n",
    "    return (model, base_model)\n",
    "\n",
    "def image_features(img,model):\n",
    "    features = np.zeros((1,2048),dtype=np.float16)\n",
    "    #model = Model(input=base_model.input, output=base_model.get_layer('flatten_1').output)\n",
    "    predictions = model.predict(img)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "model, base_model = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = Model(input=bm.input, output=bm.get_layer('flatten_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(scipy.spatial.distance.cosine(feature1,feature2),'good')\n",
    "# print(scipy.spatial.distance.cosine(feature1,feature3),'bad')\n",
    "# print(scipy.spatial.distance.cosine(feature2,feature3),'bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prefix = '/local_data/dgrossman/VeRi/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tLines = open(prefix + 'trainingLines','r')\n",
    "trainingList = list()\n",
    "for tLine in tLines:\n",
    "    tLine = tLine.strip()\n",
    "    tLine = tLine.replace('\"','')\n",
    "    parts = tLine.split(' ')\n",
    "    ldict = dict()\n",
    "    for part in parts:\n",
    "        l, r = part.split('=')\n",
    "        ldict[l]=str(r)\n",
    "    trainingList.append(ldict)\n",
    "tLines.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingList = list()\n",
    "tLines = open(prefix + 'test_features.json','r')\n",
    "for line in tLines:\n",
    "    line = line.strip()\n",
    "    line = json.loads(line)\n",
    "    trainingList.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cameraID': 'c002',\n",
       " 'colorID': '-1',\n",
       " 'imageName': '0002_c002_00030600_0.jpg',\n",
       " 'typeID': '-1',\n",
       " 'vehicleID': '0002'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0 batch 1000 images in 0.00019979476928710938 seconds\n",
      "total 1000 batch 1000 images in 19.921246767044067 seconds\n",
      "total 2000 batch 1000 images in 19.465110778808594 seconds\n",
      "total 3000 batch 1000 images in 18.9404559135437 seconds\n",
      "total 4000 batch 1000 images in 19.13255214691162 seconds\n",
      "total 5000 batch 1000 images in 18.967551469802856 seconds\n",
      "total 6000 batch 1000 images in 19.22211003303528 seconds\n",
      "total 7000 batch 1000 images in 19.369484424591064 seconds\n",
      "total 8000 batch 1000 images in 18.831890106201172 seconds\n",
      "total 9000 batch 1000 images in 18.86261248588562 seconds\n",
      "total 10000 batch 1000 images in 19.05212092399597 seconds\n",
      "total 11000 batch 1000 images in 18.88049077987671 seconds\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#outFile = open('/local_data/dgrossman/VeRi/training_features.json','w')\n",
    "outFile = open('/local_data/dgrossman/VeRi/test_features.json','w')\n",
    "\n",
    "batchSize = 1000\n",
    "start = time.time()\n",
    "for idx,line in enumerate(trainingList):\n",
    "    tempd = dict()\n",
    "    if idx % batchSize == 0:\n",
    "        end = time.time() - start\n",
    "        start = time.time()\n",
    "        print ('total {0} batch {1} images in {2} seconds'.format(idx,batchSize,end))\n",
    "    #img = load_image(prefix + 'image_train/'+line['imageName'])\n",
    "    img = load_image(prefix + 'image_test/'+line['imageName'])\n",
    "    feature = image_features(img, model) \n",
    "    tempd['resnet50'] = feature.tolist()[0]\n",
    "    tempd.update(line)\n",
    "    outFile.write(json.dumps(tempd)+'\\n')\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "funtime = open('/local_data/dgrossman/VeRi/training_features.json','r')\n",
    "work = list()\n",
    "for line in funtime:\n",
    "    line = line.strip()\n",
    "    line = json.loads(line)\n",
    "    work.append(line)\n",
    "funtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "work[0]\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Lambda\n",
    "from keras.layers import merge \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pelops.datasets.featuredataset import FeatureDataset\n",
    "from pelops.datasets.veri import VeriDataset\n",
    "from pelops.experiment_api.experiment import ExperimentGenerator\n",
    "from pelops.analysis import analysis\n",
    "from pelops.analysis.camerautil import get_match_id, make_good_bad\n",
    "import pelops.utils as utils\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import queue\n",
    "import threading\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makework(workitems,chips,cam_id=None):\n",
    "    left=chips[0]\n",
    "    right=chips[1]\n",
    "    same_vehicle = left.car_id == right.car_id\n",
    "    same_type = left.misc['vehicle_type'] == right.misc['vehicle_type']\n",
    "    same_color = left.misc['color'] == right.misc['color']\n",
    "    #same_angle = cam_id(left.cam_id) == cam_id(right.cam_id)\n",
    "    features = [same_vehicle,same_type,same_color]\n",
    "    workitems.append((left.filepath,right.filepath,features))\n",
    "    workitems.append((right.filepath,left.filepath,features))\n",
    "\n",
    "def make_examples(gen,examples):\n",
    "    workitems = []\n",
    "    \n",
    "    for _ in range(examples):\n",
    "        cameras = gen.generate()\n",
    "        match_id = get_match_id(cameras)\n",
    "        goods, bads = make_good_bad(cameras,match_id)\n",
    "        \n",
    "        makework(workitems,goods)\n",
    "        makework(workitems,bads)\n",
    "    \n",
    "    print('made',len(workitems))\n",
    "    return(workitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a GPU session and reserve memory\n",
    "def get_session(gpu_fraction=0.3):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "def rgb2bgr(x):\n",
    "    \"\"\"\n",
    "    given an array representation of an RGB image, change the image\n",
    "    into an BGR representtaion of the image\n",
    "    \"\"\"\n",
    "    return(bgr2rgb(x))\n",
    "\n",
    "\n",
    "def bgr2rgb(x):\n",
    "    \"\"\"\n",
    "    given an array representation of an BGR image, change the image\n",
    "    into an RGB representtaion of the image\n",
    "    \"\"\"\n",
    "    y = np.zeros(x.shape)\n",
    "    B = x[:,:,0]\n",
    "    G = x[:,:,1]\n",
    "    R = x[:,:,2]\n",
    "    y[:,:,0] = R\n",
    "    y[:,:,1] = G\n",
    "    y[:,:,2] = B\n",
    "    return y\n",
    "\n",
    "# load an image from disk\n",
    "# NOTE: input assumed to be RGB\n",
    "# NOTE: output is to be BGR for resnet use.\n",
    "def load_image(img_path,\n",
    "               e_dims=False,\n",
    "               image_flip=0.5,\n",
    "               image_shift=0.10,\n",
    "               image_rotate_degrees=10,\n",
    "               image_zoom=0.1,\n",
    "               output_BGR=True):\n",
    "    \"\"\"\n",
    "    WARNING this funciton should only manipulation images meant for resnet50 consumption.\n",
    "    To make it applicable for other environments remove preprocess_input.\n",
    "\n",
    "\n",
    "    Do some image manipulation\n",
    "    image input assumed to be in RGB format\n",
    "    output format default is GBR unless output_BGR is set to False\n",
    "\n",
    "    e_dims = e_dims false will output (x,y,3) sized images\n",
    "             e_domes true will output (1,x,y,3) sized images\n",
    "    image_flip = probability that image will be flipped rt to left\n",
    "    image_shift = percent of image to randomly shift up/down & right/left\n",
    "    image_rotate_degrees = rotate image randomly\n",
    "                            between [-image_rotate_degrees image_rotate_degrees]\n",
    "    image_zoom = randomly zoom image [1-image_zoom 1+image_zoom]\n",
    "    output_BGR = True -> image output will be in BGR formate RGB otherwise\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    my_img = image.img_to_array(img)\n",
    "\n",
    "    if image_flip is not None:\n",
    "        if image_flip > 1 or image_flip < -1:\n",
    "            raise ValueError('|image_flip:{0}| > 1'.format(image_flip))\n",
    "        image_flip = abs(image_flip)\n",
    "        if random.random() > image_flip :\n",
    "            my_img = image.flip_axis(my_img, axis=1)\n",
    "        \n",
    "    if image_rotate_degrees is not None:\n",
    "        image_rotate_degrees = int(image_rotate_degrees)\n",
    "        \n",
    "        if image_rotate_degrees > 360:\n",
    "            image_rotate_degrees = image_rotate_degrees % 360\n",
    "            \n",
    "        my_img = image.random_rotation(my_img,\n",
    "                                       image_rotate_degrees,\n",
    "                                       row_index=0,\n",
    "                                       col_index=1,\n",
    "                                       channel_index=2)\n",
    "    if image_shift is not None:\n",
    "        if image_shift > 1 or image_shift < -1:\n",
    "            raise ValueError('|image_shift:{0}| > 1'.format(image_shift))\n",
    "        image_shift = abs(image_shift)\n",
    "\n",
    "        my_img = image.random_shift(my_img,\n",
    "                                    image_shift,\n",
    "                                    image_shift,\n",
    "                                    row_index=0,\n",
    "                                    col_index=1,\n",
    "                                    channel_index=2)\n",
    "\n",
    "    if image_zoom is not None:\n",
    "        if image_zoom > 1 or image_zoom < -1:\n",
    "            raise ValueError('|image_zoom:{0}| > 1'.format(image_zoom))\n",
    "        image_zoom = abs(image_zoom)\n",
    "        \n",
    "        low = 1-image_zoom\n",
    "        high = 1+image_zoom\n",
    "        rng = [low,high]\n",
    "        my_img = image.random_zoom(my_img,\n",
    "                                   rng,\n",
    "                                   row_index=0,\n",
    "                                   col_index=1,\n",
    "                                   channel_index=2)\n",
    "    \n",
    "    if not output_BGR:\n",
    "        my_img = bgr2rgb(my_img)\n",
    "    \n",
    "    my_img = np.expand_dims(my_img, axis=0)\n",
    "    my_img = preprocess_input(my_img)\n",
    " \n",
    "    if not e_dims:\n",
    "        my_img = my_img.squeeze()\n",
    "\n",
    "    return my_img\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_run(history,name1,name2,rnd=None):\n",
    "    v = np.array(history[name1])\n",
    "    vc = np.array(history[name2])\n",
    "    if rnd is not None:\n",
    "        vr = np.zeros(vc.shape)\n",
    "        vr.fill(rnd)\n",
    "        b = np.array([v,vc,vr])\n",
    "    else:\n",
    "        b = np.array([v,vc])\n",
    "    c = b.transpose()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.grid(True)\n",
    "    ax.plot(c)\n",
    "    if rnd is not None:\n",
    "        ax.legend((name1,name2,'random'),\n",
    "                  bbox_to_anchor=(1, -0.05),\n",
    "                  fancybox=True, shadow=True, ncol=5)\n",
    "    else:\n",
    "       ax.legend((name1,name2),\n",
    "                  bbox_to_anchor=(1, -0.05),\n",
    "                  fancybox=True, shadow=True, ncol=5) \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_class_generator(tasking, batch_size=32,augment=False):\n",
    "    while True:\n",
    "        lefts = []\n",
    "        rights = []\n",
    "        ys = []\n",
    "        for task in random.sample(tasking, batch_size):\n",
    "            left_file = task[0]\n",
    "            right_file = task[1]\n",
    "            classes = task[2]\n",
    "            y = np.zeros(len(classes))\n",
    "            for index,c in enumerate(classes):\n",
    "                y[index] = 1 if c else 0\n",
    "            l_img = None\n",
    "            r_img = None\n",
    "            if augment:\n",
    "                l_img = load_image(left_file)\n",
    "                r_img = load_image(right_file) \n",
    "            else:\n",
    "                l_img = load_image(left_file,False,None,None,None,None)\n",
    "                r_img = load_image(right_file,False,None,None,None,None) \n",
    "            lefts.append(l_img)\n",
    "            rights.append(r_img)\n",
    "            ys.append(y)\n",
    "            \n",
    "        yield ([np.array(lefts),np.array(rights)], np.array(ys))\n",
    "\n",
    "\n",
    "def buffered_gen_mp(source_gen, buffer_size=2, num_processes=4):\n",
    "    \"\"\"\n",
    "    Generator that runs a slow source generator in a separate process.\n",
    "    buffer_size: the maximal number of items to pre-generate (length of the buffer)\n",
    "    \"\"\"\n",
    "    if buffer_size < 2:\n",
    "        raise RuntimeError(\"Minimal buffer size is 2!\")\n",
    "\n",
    "    buffer = mp.Queue(maxsize=buffer_size - 1)\n",
    "    # the effective buffer size is one less, because the generation process\n",
    "    # will generate one extra element and block until there is room in the\n",
    "    # buffer.\n",
    "\n",
    "    def _buffered_generation_process(source_gen, buffer):\n",
    "        for data in source_gen:\n",
    "            buffer.put(data, block=True)\n",
    "        buffer.put(None)  # sentinel: signal the end of the iterator\n",
    "        buffer.close()  # unfortunately this does not suffice as a signal: if buffer.get()\n",
    "        # was called and subsequently the buffer is closed, it will block\n",
    "        # forever.\n",
    "\n",
    "    for _ in range(num_processes):\n",
    "        process = mp.Process(\n",
    "            target=_buffered_generation_process, args=(source_gen, buffer))\n",
    "        process.start()\n",
    "\n",
    "    for data in iter(buffer.get, None):\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freeze(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def free_model_layers(model):\n",
    "    for layer in model.layers:\n",
    "        try:\n",
    "            if layer.name == 'resnet50':\n",
    "                print('found resnet')\n",
    "                for rn_layer in layer.layers:\n",
    "                    try:\n",
    "                        if not rn_layer.trainable:\n",
    "                            rn_layer.trainable = True\n",
    "                    except:\n",
    "                        print('rn layer not trainable',rn_layer.name)\n",
    "            if not layer.trainable:\n",
    "                layer.trainable = True\n",
    "        except:\n",
    "            if 'merge' not in layer.name.lower():\n",
    "                print('layer not trainable:', layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_siamese_model_concat(num_training_classes=3):\n",
    "\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    freeze(base_model)\n",
    "    \n",
    "    input_left = Input(shape=(224, 224, 3))\n",
    "    input_right = Input(shape=(224, 224, 3))\n",
    "\n",
    "    processed_left = base_model(input_left)\n",
    "    processed_right = base_model(input_right)\n",
    "\n",
    "    #join by slapping vectors together\n",
    "    siamese_join = merge([processed_left, processed_right], mode='concat')\n",
    "\n",
    "    my_layer = GlobalAveragePooling2D()(siamese_join)\n",
    "    my_layer = Dense(4096, activation='relu')(my_layer)\n",
    "    my_layer = BatchNormalization()(my_layer)\n",
    "    my_layer = Dense(2048, activation='relu')(my_layer)\n",
    "    my_layer = BatchNormalization()(my_layer)\n",
    "    my_layer = Dense(2048, activation='relu')(my_layer)\n",
    "    predictions = Dense(num_training_classes, activation='softmax')(my_layer)\n",
    "    model = Model([input_left, input_right], output=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def s_distance(vects):\n",
    "    x, y = vects\n",
    "    s = K.abs(x - y)\n",
    "    #s =  K.sqrt(K.square(x - y))\n",
    "    return (s)\n",
    "    #return K.squeeze(x,1) - K.squeeze(y,1)\n",
    "    \n",
    "def s_shape(shapes):\n",
    "    shape = list(shapes)\n",
    "    outshape = (shape[0])\n",
    "    return tuple(outshape)\n",
    "\n",
    "def make_siamese_model_subtract(num_training_classes=2):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    input_left = Input(shape=(224, 224, 3))\n",
    "    input_right = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    processed_left = base_model(input_left)\n",
    "    processed_right = base_model(input_right)\n",
    "    \n",
    "    #use a distance measure for making the join\n",
    "    siamese_join = Lambda(s_distance,\n",
    "                          output_shape=s_shape)([processed_left, processed_right])\n",
    "    my_layer = GlobalAveragePooling2D()(siamese_join)\n",
    "    my_layer = Dense(1024, activation='relu')(my_layer)\n",
    "    my_layer = BatchNormalization()(my_layer)\n",
    "    predictions = Dense(num_training_classes, activation='softmax')(my_layer)\n",
    "    model = Model([input_left, input_right], output=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_callbacks(model_checkpoint_format_string, tensor_board_log_dir):\n",
    "    callbacks = []\n",
    "    if model_checkpoint_format_string is not None:\n",
    "        callbacks.append(ModelCheckpoint(model_checkpoint_format_string,\n",
    "                                         monitor='loss',\n",
    "                                         verbose=1,\n",
    "                                         save_best_only=True,\n",
    "                                         save_weights_only=False,\n",
    "                                         mode='min',\n",
    "                                         period=1))\n",
    "\n",
    "    if tensor_board_log_dir is not None:\n",
    "        callbacks.append(TensorBoard(log_dir=tensor_board_log_dir,\n",
    "                                     histogram_freq=0,\n",
    "                                     write_graph=True,\n",
    "                                     write_images=False))\n",
    "\n",
    "    callbacks.append(ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       patience=10,\n",
    "                                       verbose=1,\n",
    "                                       mode='auto',\n",
    "                                       epsilon=0.0001,\n",
    "                                       cooldown=0,\n",
    "                                       min_lr=0))\n",
    "\n",
    "    callbacks.append(EarlyStopping(monitor='val_acc',\n",
    "                                   min_delta=0.003,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   mode='max'))\n",
    "    return callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set some constants\n",
    "ITEMSPERCAMERA = 2\n",
    "YRANDOM=13024\n",
    "CAMERAS=2\n",
    "DROPPED=0\n",
    "EXPERIMENTS=int(40000/4)\n",
    "batch_size = 16\n",
    "tbld = '/local_data/dgrossman/tensorboard_logs'\n",
    "mcfs = '/local_data/dgrossman/tempdir/veri-siamese.{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VeRI Version 1.0 found! Patching `typeID=0` to `typeID=2`.\n",
      "See: https://github.com/Lab41/pelops/issues/76\n",
      "made 40000\n",
      "made 40000\n"
     ]
    }
   ],
   "source": [
    "veri_validate = VeriDataset('/local_data/dgrossman/VeRi',set_type=utils.SetType.TEST.value)\n",
    "veri_train = VeriDataset('/local_data/dgrossman/VeRi',set_type = utils.SetType.TRAIN.value)\n",
    "expGen_validate = ExperimentGenerator(veri_validate, CAMERAS, ITEMSPERCAMERA, DROPPED, YRANDOM)\n",
    "expGen_train = ExperimentGenerator(veri_train, CAMERAS, ITEMSPERCAMERA, DROPPED, YRANDOM)\n",
    "training_examples = make_examples(expGen_train,EXPERIMENTS)\n",
    "validaiton_examples = make_examples(expGen_validate,EXPERIMENTS) #GROSSMAN\n",
    "#validaiton_examples = training_examples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkLabels(x):\n",
    "    s_id=0.0\n",
    "    s_type=0.0\n",
    "    s_color=0.0\n",
    "    total = len(x)\n",
    "    for v in x:\n",
    "        if v[2][0]:\n",
    "            s_id +=1\n",
    "        if v[2][1]:\n",
    "            s_type+=1\n",
    "        if v[2][2]:\n",
    "            s_color+=1\n",
    "    print ('P(s_id==1):{0} P(s_type==1):{1} P(s_color==1):{2}'.format(s_id/total,s_type/total,s_color/total))\n",
    "    return s_id/total,s_type/total,s_color/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(s_id==1):0.5 P(s_type==1):0.65045 P(s_color==1):0.58465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.65045, 0.58465)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkLabels(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(s_id==1):0.5 P(s_type==1):1.0 P(s_color==1):1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 1.0, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkLabels(validaiton_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GROSSMAN change augment to True when running for real.\n",
    "\n",
    "train_buffered_generator_mp = buffered_gen_mp(image_class_generator(training_examples,\n",
    "                                                                    batch_size,\n",
    "                                                                    augment=False),\n",
    "                                              buffer_size=20,\n",
    "                                              num_processes=5)\n",
    "\n",
    "val_buffered_generator_mp = buffered_gen_mp(image_class_generator(validaiton_examples,\n",
    "                                                                  batch_size,\n",
    "                                                                  augment=False),\n",
    "                                            buffer_size=20,\n",
    "                                            num_processes=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = make_callbacks(mcfs,tbld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KTF.set_session(get_session(.90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = make_siamese_model_concat(3)\n",
    "model = make_siamese_model_subtract(3)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed_history = model.fit_generator(train_buffered_generator_mp,\n",
    "                                        samples_per_epoch=10240,\n",
    "                                        nb_epoch=50,\n",
    "                                        callbacks=None,\n",
    "                                        nb_val_samples=10240,\n",
    "                                        validation_data=val_buffered_generator_mp,\n",
    "                                        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_run(fixed_history.history,'acc','val_acc',0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "free_model_layers(model)\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "free_history = model.fit_generator(train_buffered_generator_mp,\n",
    "                                   samples_per_epoch=10240,\n",
    "                                   nb_epoch=50,\n",
    "                                   callbacks=None,\n",
    "                                   nb_val_samples=10240,\n",
    "                                   validation_data=val_buffered_generator_mp,\n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_run(free_history.history,'acc','val_acc',0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_run(free_history.history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    try:\n",
    "        print(layer.name,layer.trainable)\n",
    "    except:\n",
    "        print('layer not trainable:', layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rn = model.get_layer('resnet50')\n",
    "for layer in rn.layers:\n",
    "    try:\n",
    "        print(layer.name,layer.trainable)\n",
    "    except:\n",
    "        print('layer not trainable:', layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

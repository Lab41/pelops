{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Lambda\n",
    "from keras.layers import merge \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pelops.datasets.featuredataset import FeatureDataset\n",
    "from pelops.datasets.veri import VeriDataset\n",
    "from pelops.experiment_api.experiment import ExperimentGenerator\n",
    "from pelops.analysis import analysis\n",
    "from pelops.analysis.camerautil import get_match_id, make_good_bad\n",
    "import pelops.utils as utils\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from pelops.utils import train_test_key_filter\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import queue\n",
    "import threading\n",
    "import numpy as np\n",
    "import datetime\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_workaround(model, model_output_file, weights_output_file):\n",
    "    print('saving model   to {}'.format(model_output_file))\n",
    "    print('saving weights to {}'.format(weights_output_file))\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_output_file, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(weights_output_file)\n",
    "\n",
    "\n",
    "def load_model_workaround(model_output_file, weights_output_file):\n",
    "    # load json and create model\n",
    "    json_file = open(model_output_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weights_output_file)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makework(workitems,chips,cam_id=None):\n",
    "    left=chips[0]\n",
    "    right=chips[1]\n",
    "    same_vehicle = left.car_id == right.car_id\n",
    "    same_type = left.misc['vehicle_type'] == right.misc['vehicle_type']\n",
    "    same_color = left.misc['color'] == right.misc['color']\n",
    "    #same_angle = cam_id(left.cam_id) == cam_id(right.cam_id)\n",
    "    features = [same_vehicle,same_type,same_color]\n",
    "    workitems.append((left.filepath,right.filepath,features))\n",
    "    workitems.append((right.filepath,left.filepath,features))\n",
    "\n",
    "def make_examples(gen,examples):\n",
    "    workitems = []\n",
    "    \n",
    "    for _ in range(examples):\n",
    "        cameras = gen.generate()\n",
    "        match_id = get_match_id(cameras)\n",
    "        goods, bads = make_good_bad(cameras,match_id)\n",
    "        \n",
    "        makework(workitems,goods)\n",
    "        makework(workitems,bads)\n",
    "    \n",
    "    print('made',len(workitems))\n",
    "    return(workitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a GPU session and reserve memory\n",
    "def get_session(gpu_fraction=0.3):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "def rgb2bgr(x):\n",
    "    \"\"\"\n",
    "    given an array representation of an RGB image, change the image\n",
    "    into an BGR representtaion of the image\n",
    "    \"\"\"\n",
    "    return(bgr2rgb(x))\n",
    "\n",
    "\n",
    "def bgr2rgb(x):\n",
    "    \"\"\"\n",
    "    given an array representation of an BGR image, change the image\n",
    "    into an RGB representtaion of the image\n",
    "    \"\"\"\n",
    "    y = np.zeros(x.shape)\n",
    "    B = x[:,:,0]\n",
    "    G = x[:,:,1]\n",
    "    R = x[:,:,2]\n",
    "    y[:,:,0] = R\n",
    "    y[:,:,1] = G\n",
    "    y[:,:,2] = B\n",
    "    return y\n",
    "\n",
    "# load an image from disk\n",
    "# NOTE: input assumed to be RGB\n",
    "# NOTE: output is to be BGR for resnet use.\n",
    "def load_image(img_path,\n",
    "               e_dims=False,\n",
    "               image_flip=0.5,\n",
    "               image_shift=0.20,\n",
    "               image_rotate_degrees=90,\n",
    "               image_zoom=0.15,\n",
    "               output_BGR=True):\n",
    "    \"\"\"\n",
    "    WARNING this funciton should only manipulation images meant for resnet50 consumption.\n",
    "    To make it applicable for other environments remove preprocess_input.\n",
    "\n",
    "\n",
    "    Do some image manipulation\n",
    "    image input assumed to be in RGB format\n",
    "    output format default is GBR unless output_BGR is set to False\n",
    "\n",
    "    e_dims = e_dims false will output (x,y,3) sized images\n",
    "             e_domes true will output (1,x,y,3) sized images\n",
    "    image_flip = probability that image will be flipped rt to left\n",
    "    image_shift = percent of image to randomly shift up/down & right/left\n",
    "    image_rotate_degrees = rotate image randomly\n",
    "                            between [-image_rotate_degrees image_rotate_degrees]\n",
    "    image_zoom = randomly zoom image [1-image_zoom 1+image_zoom]\n",
    "    output_BGR = True -> image output will be in BGR formate RGB otherwise\n",
    "    \"\"\"\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    my_img = image.img_to_array(img)\n",
    "\n",
    "    if image_flip is not None:\n",
    "        if image_flip > 1 or image_flip < -1:\n",
    "            raise ValueError('|image_flip:{0}| > 1'.format(image_flip))\n",
    "        image_flip = abs(image_flip)\n",
    "        if random.random() > image_flip :\n",
    "            my_img = image.flip_axis(my_img, axis=1)\n",
    "        \n",
    "    if image_rotate_degrees is not None:\n",
    "        image_rotate_degrees = int(image_rotate_degrees)\n",
    "        \n",
    "        if image_rotate_degrees > 360:\n",
    "            image_rotate_degrees = image_rotate_degrees % 360\n",
    "            \n",
    "        my_img = image.random_rotation(my_img,\n",
    "                                       image_rotate_degrees,\n",
    "                                       row_index=0,\n",
    "                                       col_index=1,\n",
    "                                       channel_index=2)\n",
    "    if image_shift is not None:\n",
    "        if image_shift > 1 or image_shift < -1:\n",
    "            raise ValueError('|image_shift:{0}| > 1'.format(image_shift))\n",
    "        image_shift = abs(image_shift)\n",
    "\n",
    "        my_img = image.random_shift(my_img,\n",
    "                                    image_shift,\n",
    "                                    image_shift,\n",
    "                                    row_index=0,\n",
    "                                    col_index=1,\n",
    "                                    channel_index=2)\n",
    "\n",
    "    if image_zoom is not None:\n",
    "        if image_zoom > 1 or image_zoom < -1:\n",
    "            raise ValueError('|image_zoom:{0}| > 1'.format(image_zoom))\n",
    "        image_zoom = abs(image_zoom)\n",
    "        \n",
    "        low = 1-image_zoom\n",
    "        high = 1+image_zoom\n",
    "        rng = [low,high]\n",
    "        my_img = image.random_zoom(my_img,\n",
    "                                   rng,\n",
    "                                   row_index=0,\n",
    "                                   col_index=1,\n",
    "                                   channel_index=2)\n",
    "    \n",
    "    if not output_BGR:\n",
    "        my_img = bgr2rgb(my_img)\n",
    "    \n",
    "    my_img = np.expand_dims(my_img, axis=0)\n",
    "    my_img = preprocess_input(my_img)\n",
    " \n",
    "    if not e_dims:\n",
    "        my_img = my_img.squeeze()\n",
    "\n",
    "    return my_img\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_run(history,name1,name2,rnd=None):\n",
    "    \"\"\"\n",
    "    Take the output of a model.\n",
    "    \"\"\"\n",
    "    v = np.array(history[name1])\n",
    "    vc = np.array(history[name2])\n",
    "    if rnd is not None:\n",
    "        vr = np.zeros(vc.shape)\n",
    "        vr.fill(rnd)\n",
    "        b = np.array([v,vc,vr])\n",
    "    else:\n",
    "        b = np.array([v,vc])\n",
    "    c = b.transpose()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.grid(True)\n",
    "    ax.plot(c)\n",
    "    if rnd is not None:\n",
    "        ax.legend((name1,name2,'random'),\n",
    "                  bbox_to_anchor=(1, -0.05),\n",
    "                  fancybox=True, shadow=True, ncol=5)\n",
    "    else:\n",
    "       ax.legend((name1,name2),\n",
    "                  bbox_to_anchor=(1, -0.05),\n",
    "                  fancybox=True, shadow=True, ncol=5) \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_class_generator(tasking, batch_size=32,augment=False):\n",
    "    \"\"\"\n",
    "    Offload the augmentation of images, create images in batch_size chunks\n",
    "    augment=False -> return image  augment=True -> return augmented image\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        lefts = []\n",
    "        rights = []\n",
    "        ys = []\n",
    "        for task in random.sample(tasking, batch_size):\n",
    "            left_file = task[0]\n",
    "            right_file = task[1]\n",
    "            classes = task[2]\n",
    "            y = np.zeros(len(classes))\n",
    "            for index,c in enumerate(classes):\n",
    "                y[index] = 1 if c else 0\n",
    "            l_img = None\n",
    "            r_img = None\n",
    "            if augment:\n",
    "                l_img = load_image(left_file)\n",
    "                r_img = load_image(right_file) \n",
    "            else:\n",
    "                l_img = load_image(left_file,False,None,None,None,None)\n",
    "                r_img = load_image(right_file,False,None,None,None,None) \n",
    "            lefts.append(l_img)\n",
    "            rights.append(r_img)\n",
    "            ys.append(y)\n",
    "            \n",
    "        yield ([np.array(lefts),np.array(rights)], np.array(ys))\n",
    "\n",
    "\n",
    "def buffered_gen_mp(source_gen, buffer_size=2, num_processes=4):\n",
    "    \"\"\"\n",
    "    Generator that runs a slow source generator in a separate process.\n",
    "    buffer_size: the maximal number of items to pre-generate (length of the buffer)\n",
    "    \"\"\"\n",
    "    if buffer_size < 2:\n",
    "        raise RuntimeError(\"Minimal buffer size is 2!\")\n",
    "\n",
    "    buffer = mp.Queue(maxsize=buffer_size - 1)\n",
    "    # the effective buffer size is one less, because the generation process\n",
    "    # will generate one extra element and block until there is room in the\n",
    "    # buffer.\n",
    "\n",
    "    def _buffered_generation_process(source_gen, buffer):\n",
    "        for data in source_gen:\n",
    "            buffer.put(data, block=True)\n",
    "        buffer.put(None)  # sentinel: signal the end of the iterator\n",
    "        buffer.close()  # unfortunately this does not suffice as a signal: if buffer.get()\n",
    "        # was called and subsequently the buffer is closed, it will block\n",
    "        # forever.\n",
    "\n",
    "    for _ in range(num_processes):\n",
    "        process = mp.Process(\n",
    "            target=_buffered_generation_process, args=(source_gen, buffer))\n",
    "        process.start()\n",
    "\n",
    "    for data in iter(buffer.get, None):\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(model):\n",
    "    \"\"\"\n",
    "    Make model untrainable\n",
    "    \"\"\"\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_model_layers(model):\n",
    "    \"\"\"\n",
    "    Make the model trainable\n",
    "    \"\"\"\n",
    "    for layer in model.layers:\n",
    "        try:\n",
    "            if layer.name == 'resnet50':\n",
    "                print('found resnet')\n",
    "                for rn_layer in layer.layers:\n",
    "                    try:\n",
    "                        if not rn_layer.trainable:\n",
    "                            rn_layer.trainable = True\n",
    "                    except:\n",
    "                        print('rn layer not trainable',rn_layer.name)\n",
    "            if not layer.trainable:\n",
    "                layer.trainable = True\n",
    "        except:\n",
    "            if 'merge' not in layer.name.lower():\n",
    "                print('layer not trainable:', layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model_concat(num_training_classes=3):\n",
    "    \"\"\"\n",
    "    Siamese network created via concatenating resnet50 outputs\n",
    "    \n",
    "    @TODO see if less layers can now be used because of not using\n",
    "    binary_crossentropy..\n",
    "    \"\"\"\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    freeze(base_model)\n",
    "    \n",
    "    input_left = Input(shape=(224, 224, 3))\n",
    "    input_right = Input(shape=(224, 224, 3))\n",
    "\n",
    "    processed_left = base_model(input_left)\n",
    "    processed_right = base_model(input_right)\n",
    "\n",
    "    #join by slapping vectors together\n",
    "    siamese_join = merge([processed_left, processed_right], mode='concat')\n",
    "\n",
    "    my_layer = GlobalAveragePooling2D()(siamese_join)\n",
    "    my_layer = Dense(4096, activation='relu')(my_layer)\n",
    "    my_layer = BatchNormalization()(my_layer)\n",
    "    my_layer = Dense(2048, activation='relu')(my_layer)\n",
    "    my_layer = BatchNormalization()(my_layer)\n",
    "    my_layer = Dense(2048, activation='relu')(my_layer)\n",
    "    predictions = Dense(num_training_classes, activation='sigmoid')(my_layer)\n",
    "    model = Model([input_left, input_right], output=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_distance(vects):\n",
    "    \"\"\"\n",
    "    return the abs difference between vectors\n",
    "    \"\"\"\n",
    "    x, y = vects\n",
    "    s = K.abs(x - y)\n",
    "    #s =  K.sqrt(K.square(x - y))\n",
    "    return (s)\n",
    "    #return K.squeeze(x,1) - K.squeeze(y,1)\n",
    "    \n",
    "def s_shape(shapes):\n",
    "    \"\"\"\n",
    "    return the sape of the vector being used\n",
    "    \"\"\"\n",
    "    shape = list(shapes)\n",
    "    outshape = (shape[0])\n",
    "    return tuple(outshape)\n",
    "\n",
    "def make_siamese_model_subtract(num_training_classes=2):\n",
    "    \"\"\"\n",
    "    Siamese network created via subtracting resnet50 outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    input_left = Input(shape=(224, 224, 3))\n",
    "    input_right = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    processed_left = base_model(input_left)\n",
    "    processed_right = base_model(input_right)\n",
    "    \n",
    "    #use a distance measure for making the join\n",
    "    siamese_join = Lambda(s_distance,\n",
    "                          output_shape=s_shape)([processed_left, processed_right])\n",
    "    my_layer = GlobalAveragePooling2D()(siamese_join)\n",
    "    my_layer = Dense(1024, activation='relu')(my_layer)\n",
    "    my_layer = BatchNormalization()(my_layer)\n",
    "    predictions = Dense(num_training_classes, activation='sigmoid')(my_layer)\n",
    "    model = Model([input_left, input_right], output=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_callbacks(model_checkpoint_format_string, tensor_board_log_dir):\n",
    "    \"\"\"\n",
    "    programatically make the callbacks to be used for training\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "    if model_checkpoint_format_string is not None:\n",
    "        callbacks.append(ModelCheckpoint(model_checkpoint_format_string,\n",
    "                                         monitor='loss',\n",
    "                                         verbose=1,\n",
    "                                         save_best_only=True,\n",
    "                                         save_weights_only=False,\n",
    "                                         mode='min',\n",
    "                                         period=1))\n",
    "\n",
    "    if tensor_board_log_dir is not None:\n",
    "        callbacks.append(TensorBoard(log_dir=tensor_board_log_dir,\n",
    "                                     histogram_freq=0,\n",
    "                                     write_graph=True,\n",
    "                                     write_images=False))\n",
    "\n",
    "    callbacks.append(ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       patience=10,\n",
    "                                       verbose=1,\n",
    "                                       mode='min',\n",
    "                                       epsilon=0.0001,\n",
    "                                       cooldown=0,\n",
    "                                       min_lr=0))\n",
    "\n",
    "    callbacks.append(EarlyStopping(monitor='val_acc',\n",
    "                                   min_delta=0.003,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   mode='max'))\n",
    "    return callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLabels(x):\n",
    "    \"\"\"\n",
    "    Make a warm fuzzy about the classes being balanced\n",
    "    \"\"\"\n",
    "    s_id=0.0\n",
    "    s_type=0.0\n",
    "    s_color=0.0\n",
    "    total = len(x)\n",
    "    for v in x:\n",
    "        if v[2][0]:\n",
    "            s_id +=1\n",
    "        if v[2][1]:\n",
    "            s_type+=1\n",
    "        if v[2][2]:\n",
    "            s_color+=1\n",
    "    print ('P(s_id==1):{0} P(s_type==1):{1} P(s_color==1):{2}'.format(s_id/total,s_type/total,s_color/total))\n",
    "    return s_id/total,s_type/total,s_color/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashint(i):\n",
    "    \"\"\"\n",
    "    return the hash of an int\n",
    "    \"\"\"\n",
    "    m = m = hashlib.md5()\n",
    "    m.update(i)\n",
    "    return m.hexdigest()\n",
    "\n",
    "def split_veri_train(gen,num=70):\n",
    "    \"\"\"\n",
    "    help split the testing and training sets\n",
    "    num=70 vehicles removed form training and will\n",
    "    be used in validation\n",
    "    \"\"\"\n",
    "    hashes = {}\n",
    "    \n",
    "    for car in gen.valid_target_cars.keys():\n",
    "        hashes[car] = car\n",
    "\n",
    "    a = [x for x in hashes.keys()]\n",
    "    a = a[:num]\n",
    "\n",
    "    test_array = []\n",
    "    valid_array = []\n",
    "\n",
    "    for item in gen.valid_target_cars.keys():\n",
    "        if item in a:\n",
    "            valid_array.append(item)\n",
    "        else:\n",
    "            test_array.append(item)\n",
    "    return sorted(test_array), sorted(valid_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set some constants\n",
    "ITEMSPERCAMERA = 2\n",
    "YRANDOM=13024\n",
    "CAMERAS=2\n",
    "DROPPED=0\n",
    "EXPERIMENTS=int(40000/4)\n",
    "batch_size = 16\n",
    "tbld = '/local_data/dgrossman/tensorboard_logs'\n",
    "mcfs = '/local_data/dgrossman/tempdir/veri-siamese.{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_validate = VeriDataset('/local_data/dgrossman/VeRi',set_type=utils.SetType.TEST.value)\n",
    "veri_train = VeriDataset('/local_data/dgrossman/VeRi',set_type = utils.SetType.TRAIN.value)\n",
    "expGen_validate = ExperimentGenerator(veri_train,\n",
    "                                      CAMERAS,\n",
    "                                      ITEMSPERCAMERA,\n",
    "                                      DROPPED,\n",
    "                                      YRANDOM,\n",
    "                                      key_filter=partial(train_test_key_filter, split=\"test\"))\n",
    "\n",
    "expGen_train = ExperimentGenerator(veri_train,\n",
    "                                   CAMERAS,\n",
    "                                   ITEMSPERCAMERA,\n",
    "                                   DROPPED,\n",
    "                                   YRANDOM,\n",
    "                                   key_filter=partial(train_test_key_filter, split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expGen_train.generate();\n",
    "#expGen_validate.generate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst,val = split_veri_train(expGen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expGen_train.list_valid_target_cars = list(\n",
    "#    filter(\n",
    "#        lambda x: x in tst, \n",
    "#        sorted(expGen_train.valid_target_cars.keys())\n",
    "#    ))\n",
    "#\n",
    "#expGen_validate.list_valid_target_cars = list(\n",
    "#    filter(\n",
    "#        lambda x: x in val, \n",
    "#        sorted(expGen_validate.valid_target_cars.keys())\n",
    "#    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = make_examples(expGen_train,EXPERIMENTS)\n",
    "validaiton_examples = make_examples(expGen_validate,EXPERIMENTS) #GROSSMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkLabels(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkLabels(validaiton_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROSSMAN change augment to True when running for real.\n",
    "\n",
    "train_buffered_generator_mp = buffered_gen_mp(image_class_generator(training_examples,\n",
    "                                                                    batch_size,\n",
    "                                                                    augment=True),\n",
    "                                              buffer_size=20,\n",
    "                                              num_processes=5)\n",
    "\n",
    "val_buffered_generator_mp = buffered_gen_mp(image_class_generator(validaiton_examples,\n",
    "                                                                  batch_size,\n",
    "                                                                  augment=False),\n",
    "                                            buffer_size=20,\n",
    "                                            num_processes=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = make_callbacks(mcfs,tbld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KTF.set_session(get_session(.90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = make_siamese_model_concat(3)\n",
    "model = make_siamese_model_subtract(3)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_history = model.fit_generator(train_buffered_generator_mp,\n",
    "                                        samples_per_epoch=10240,\n",
    "                                        nb_epoch=20,\n",
    "                                        callbacks=None,\n",
    "                                        nb_val_samples=10240,\n",
    "                                        validation_data=val_buffered_generator_mp,\n",
    "                                        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_run(fixed_history.history,'acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_run(fixed_history.history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_model_layers(model)\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_history = model.fit_generator(train_buffered_generator_mp,\n",
    "                                   samples_per_epoch=10240,\n",
    "                                   nb_epoch=50,\n",
    "                                   callbacks=callbacks,\n",
    "                                   nb_val_samples=10240,\n",
    "                                   validation_data=val_buffered_generator_mp,\n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_run(free_history.history,'acc','val_acc',0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_run(free_history.history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    try:\n",
    "        print(layer.name,layer.trainable)\n",
    "    except:\n",
    "        print('layer not trainable:', layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = model.get_layer('resnet50')\n",
    "for layer in rn.layers:\n",
    "    try:\n",
    "        print(layer.name,layer.trainable)\n",
    "    except:\n",
    "        print('layer not trainable:', layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_workaround(model, '/local_data/dgrossman/model_save_dir/VeRi-siamese-weekend.model.json', '/local_data/dgrossman/model_save_dir/VeRi-siamese-weekend.weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_workaround('/local_data/dgrossman/model_save_dir/VeRi-siamese-weekend.model.json', '/local_data/dgrossman/model_save_dir/VeRi-siamese-weekend.weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(model,left,right):\n",
    "    l_img = load_image(left_file,True,None,None,None,None)\n",
    "    r_img = load_image(right_file,True,None,None,None,None)\n",
    "    #print('P(sameCAR),P(sameModelCar),P(sameColorCar)')\n",
    "    outcomes = model.predict([l_img,r_img]).squeeze()\n",
    "    fig = plt.figure()\n",
    "    plot_image = np.concatenate((image.array_to_img(l_img.squeeze()), image.array_to_img(r_img.squeeze())), axis=1)\n",
    "    fig.suptitle('P(sameCar):{0:0.2f} P(sameModelCar):{1:0.2f} P(sameColorCar):{2:0.2f}'.format(outcomes[0],outcomes[1],outcomes[2]))\n",
    "    plt.imshow(plot_image)\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plot_image = np.concatenate((image.array_to_img(l_img.squeeze()), image.array_to_img(r_img.squeeze())), axis=1)\n",
    "    fig.suptitle('P(sameCar):{0:0.2f} P(sameModelCar):{1:0.2f} P(sameColorCar):{2:0.2f}'.format(outcomes[0],outcomes[1],outcomes[2]))\n",
    "    plt.imshow(plot_image)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_file = '/local_data/dgrossman/VeRi/image_test/0473_c010_00030540_0.jpg'\n",
    "right_file = '/local_data/dgrossman/VeRi/image_test/0473_c019_00004610_0.jpg'\n",
    "#right_file = '/local_data/dgrossman/VeRi/image_test/0306_c003_00016565_0.jpg'\n",
    "compare(model,left_file,right_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

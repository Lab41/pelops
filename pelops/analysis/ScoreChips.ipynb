{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pelops.datasets.chipper import FrameProducer, ExtractedChip, Methods, Chipper\n",
    "import cv2\n",
    "from hdfs3 import HDFileSystem\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import namedtuple\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HDFS IP address or node name\n",
    "hdfs_location = '0.0.0.0'\n",
    "\n",
    "# Set Texas ('TX') data source, path to videos and camera name\n",
    "data_source = 'TX'\n",
    "video_location = '/datasets/texas_dot/Ending20160903/user/*.mp4'\n",
    "camera_name = 'IH37_Jones' \n",
    "#camera_name = 'IH10_Martin'\n",
    "#camera_name = 'IH37_9th'\n",
    "\n",
    "# Set Louisiana ('LA') data source, path to videos and camera name\n",
    "#data_source = 'LA'\n",
    "#video_location = '/datasets/louisiana_dot/72/*.mp4'\n",
    "#camera_name = 'Claiborne1'\n",
    "\n",
    "# Set xml path and labeled path \n",
    "xml_basepath = '/data/fs4/teams/pelops/labelme/annotations/'\n",
    "image_path = '/data/fs4/teams/pelops/labelme/images/{}'\n",
    "\n",
    "# Set kernel, threshold and chipping method parameter space\n",
    "candidate_kernel_sizes = [(5,5),(9,9),(11,11),(15,15),(21,21),(29,29),(33,33)]\n",
    "candidate_thresholds = [2,4,6,8,10,12,15,17,20,27,33,40,50]\n",
    "candidate_chipping_methods = [Methods.BACKGROUND_SUB, Methods.OPENCV]\n",
    "\n",
    "# Set maximum number of top chip scoring results to display\n",
    "topn = 10\n",
    "\n",
    "# Toggle creation of chipping accuracy visualizations\n",
    "retain_visualizations = False\n",
    "\n",
    "# Toggle applying an input mask; Set mask input parameters for apply_mask function in next cell \n",
    "apply_input_mask = False\n",
    "\n",
    "# Toggle expanding the boundary box dimensions; Set box parameter 'amount' for expand_box function in next cell \n",
    "apply_box_expander = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to HDFS and obtain video filenames\n",
    "hdfs = HDFileSystem(host=hdfs_location, port=8020)\n",
    "filenames = hdfs.glob(video_location)\n",
    "\n",
    "# Format filenames to use as key in sorting\n",
    "def get_info(filename):\n",
    "    bname = os.path.basename(filename)\n",
    "    if data_source=='TX':\n",
    "        # File naming convention for Texas uses dashes between timestamps\n",
    "        return bname.split('-')[0], int(bname.split('-')[1])\n",
    "    elif data_source=='LA':\n",
    "        # File naming convention for Louisiana uses underscores inside timestamp elements\n",
    "        return bname.split('_')[0], int(bname.split('_')[1]+bname.split('_')[2]+bname.split('_')[3]+bname.split('_')[4]+bname.split('_')[5].split('.')[0])\n",
    "\n",
    "# Sort filenames and filter based on camera name, order by timestamp\n",
    "filenames = sorted(filenames, key=get_info)\n",
    "filenames_filtered = [filename for filename in filenames if camera_name in filename]\n",
    "\n",
    "# Creates FrameProducer generator object from first video (by timestamp) in filenames_filtered \n",
    "# There needs to be truth data for this video in xml_basepath\n",
    "fp = FrameProducer([filenames_filtered[0]], hdfs.open)\n",
    "\n",
    "# Sets numpy array elements on image input_arry to 0 at specific indices based on input data\n",
    "# ex: input_mask_top=60 will set first 60 rows of image array to 0\n",
    "def apply_mask(input_arry,input_mask_top=80,input_mask_bottom=300):\n",
    "    input_arry[:input_mask_top]=0\n",
    "    input_arry[input_mask_bottom:]=0\n",
    "    return input_arry\n",
    "\n",
    "# Increase boundary box size; Used with box_expander parameter of Chipper class\n",
    "def expand_box(x,y,w,h, amount=5):\n",
    "    return x-amount, y-amount, w+amount*2, h+amount*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function \n",
    "# get_frame_lookup - Takes frame and outputs frame_lookup and chips\n",
    "# Input\n",
    "# fp - FrameProducer object \n",
    "# kernel_size - Size of convolutional kernel, default=(25,25) and must be odd numbers\n",
    "# threshold - Threshold value used in OpenCV's threshold function, default=30\n",
    "# chipping_method - Type of chipping, default = Methods.BACKGROUND_SUB\n",
    "# Output\n",
    "# frame_lookup - Dictionary of chip reference values keyed on frame_numbers \n",
    "# chips - List of Chipper objects\n",
    "\n",
    "def get_frame_lookup(fp, \n",
    "                     kernel_size=(25,25), \n",
    "                     threshold=30, \n",
    "                     chipping_method=Methods.BACKGROUND_SUB,\n",
    "                     mask_modifier=None,\n",
    "                     box_expander=None\n",
    "                    ):\n",
    "    chipper = Chipper(fp, \n",
    "                  mask_modifier=mask_modifier,\n",
    "                  kernel_size = kernel_size,\n",
    "                  threshold = threshold,\n",
    "                  box_expander=box_expander,\n",
    "                  chipping_method=chipping_method)\n",
    "\n",
    "    # Get chips by frame number\n",
    "    chips = []\n",
    "    for frame_chips in chipper:\n",
    "        chips.extend(frame_chips)\n",
    "\n",
    "    from collections import defaultdict\n",
    "    frame_lookup = defaultdict(list)\n",
    "    for ec in chips:\n",
    "        frame_lookup[ec.frame_number].append(ec)\n",
    "    return frame_lookup, chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get XML file name based on orignal image file name and frame\n",
    "def get_xml_name(filename, frame_number):   \n",
    "    return '{}_{}_.xml'.format(os.path.basename(filename),frame_number)\n",
    "\n",
    "# Define namedtuple for bounding box attributes\n",
    "BBox =namedtuple('BBox', ['x','y', 'w', 'h'])\n",
    "\n",
    "# Take list of polygon dimensions and return bounding box dimensions of X,Y,width,height \n",
    "def get_x_y_w_h(bbox):\n",
    "    xs = [x for x,y in bbox]\n",
    "    ys = [y for x,y in bbox]\n",
    "    min_x = min(xs)\n",
    "    min_y = min(ys)\n",
    "    max_x = max(xs)\n",
    "    max_y = max(ys)\n",
    "    return BBox(x=min_x, \n",
    "                y=min_y, \n",
    "                w=max_x-min_x, \n",
    "                h=max_y-min_y)\n",
    "\n",
    "# Obtain bounding boxes from XML objects, return frame_filename and bounding boxes\n",
    "def get_bboxes_from_xml(xml_obj):\n",
    "    for top_level_tag in xml_obj.iter('filename'):\n",
    "        frame_filename = top_level_tag.text\n",
    "    bboxes = []\n",
    "    for top_level_tag in xml_obj.iter('object'):\n",
    "        for polygon in top_level_tag.iter('polygon'):\n",
    "            pts = []\n",
    "            for pt in polygon.iter('pt'):\n",
    "                x = None\n",
    "                y = None\n",
    "                for dim in pt.iter():\n",
    "                    if dim.tag == 'x':\n",
    "                        x = int(dim.text)\n",
    "                    elif dim.tag == 'y':\n",
    "                        y = int(dim.text)\n",
    "                if x and y:\n",
    "                    pts.append((x,y))\n",
    "            bboxes.append(get_x_y_w_h(pts))\n",
    "    return frame_filename, bboxes\n",
    "\n",
    "# Obtain bounding boxes from filename\n",
    "def get_bboxes_from_file(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    return get_bboxes_from_xml(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build xml_files_lookup dictionary from xml_basepath\n",
    "xml_files_lookup = {}\n",
    "for filename in glob.glob(os.path.join(xml_basepath, '*')):\n",
    "    xml_files_lookup[os.path.basename(filename)] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find intersection union score for two bounding boxes and return X,Y,width,height\n",
    "def get_intersection_union(bbox1, bbox2):\n",
    "    # Top left of intersection\n",
    "    xA = max(bbox1.x, bbox2.x)\n",
    "    yA = max(bbox1.y, bbox2.y)\n",
    "    \n",
    "    # Bottom right\n",
    "    xB = min(bbox1.x+bbox1.w, bbox2.x+bbox2.w)\n",
    "    yB = min(bbox1.y+bbox1.h, bbox2.y+bbox2.h)\n",
    "    width = xB-xA\n",
    "    height = yB-yA\n",
    "    if width < 0 or height < 0:\n",
    "        return None\n",
    "    return (xA, yA, width, height)\n",
    "\n",
    "# Calculate intersection over union (IoU) score for two bounding boxes\n",
    "def get_iou(bbox1, bbox2):\n",
    "    # Top left of intersection\n",
    "    xA = max(bbox1.x, bbox2.x)\n",
    "    yA = max(bbox1.y, bbox2.y)\n",
    "    \n",
    "    # Bottom right\n",
    "    xB = min(bbox1.x+bbox1.w, bbox2.x+bbox2.w)\n",
    "    yB = min(bbox1.y+bbox1.h, bbox2.y+bbox2.h)\n",
    "    width = xB-xA\n",
    "    height = yB-yA\n",
    "    if width < 0 or height < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        intersectionArea = (xB - xA + 1) * (yB - yA + 1)\n",
    "        unionArea = bbox1.w*bbox1.h + bbox2.w*bbox2.h\n",
    "        \n",
    "        return intersectionArea/float(unionArea - intersectionArea)\n",
    "\n",
    "    return (xA, yA, width, height)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visually plot performance of predicted bounding box and ground truth bounding box for filename\n",
    "def visualize_perf(filename, bboxes1, bboxes2):\n",
    "    frame = Image.open(image_path.format(filename))\n",
    "    frame = np.uint8(frame)\n",
    "    for box in bboxes1:\n",
    "        x, y, w, h = box.x, box.y, box.w, box.h\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "    for box in bboxes2:\n",
    "        x, y, w, h = box.x, box.y, box.w, box.h\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),1)    \n",
    "    intersection = get_intersection_union(bboxes1[0], bboxes2[0])\n",
    "    if intersection:\n",
    "        x,y,w,h = intersection\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),5)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Score performance of chipping against ground truth for list of frames and associated chips\n",
    "def score_frame_lookup(frame_lookup, chips):\n",
    "    video_ious = []\n",
    "    plots = []\n",
    "    for frame_number in sorted(frame_lookup):\n",
    "        chips = frame_lookup[frame_number]\n",
    "        bname = os.path.basename(chips[0].filename)\n",
    "        xml_filename = get_xml_name(bname, frame_number)\n",
    "        if xml_filename in xml_files_lookup:\n",
    "            xml_full_filename = xml_files_lookup[xml_filename]\n",
    "            frame_image, truth_bboxes = get_bboxes_from_file(xml_full_filename)\n",
    "            found_bboxes = []\n",
    "            for chip in chips:\n",
    "                found_bboxes.append((chip.x, chip.y, chip.w, chip.h))\n",
    "            frame_ious = []\n",
    "            for truth_bbox in truth_bboxes:\n",
    "                box_ious = []\n",
    "                for chip in chips:\n",
    "                    box_ious.append(get_iou(chip, truth_bbox))\n",
    "                frame_ious.append(max(box_ious))\n",
    "            video_ious.append(np.mean(frame_ious))\n",
    "            if retain_visualizations:\n",
    "                frame = visualize_perf(frame_image, truth_bboxes, chips)\n",
    "                plots.append(frame)\n",
    "    return np.mean(video_ious), plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing kernel (5, 5)\n",
      "Processing kernel (9, 9)\n",
      "Processing kernel (11, 11)\n",
      "Processing kernel (15, 15)\n",
      "Processing kernel (21, 21)\n",
      "Processing kernel (29, 29)\n",
      "Processing kernel (33, 33)\n"
     ]
    }
   ],
   "source": [
    "# Calculate chipping scores\n",
    "score_strings = []\n",
    "visualizations = []\n",
    "\n",
    "if apply_input_mask:\n",
    "    mask_modifier = apply_mask\n",
    "else:\n",
    "    mask_modifier = None\n",
    "if apply_box_expander:\n",
    "    box_expander = expand_box\n",
    "else:\n",
    "    box_expander = None\n",
    "\n",
    "for kernel_size in candidate_kernel_sizes:\n",
    "    print(\"Processing kernel\",kernel_size)\n",
    "    for threshold in candidate_thresholds:\n",
    "        for chipping_method in candidate_chipping_methods:\n",
    "            frame_lookup, chips = get_frame_lookup(fp, \n",
    "                            kernel_size=kernel_size,\n",
    "                            threshold=threshold, \n",
    "                            chipping_method=chipping_method,\n",
    "                            mask_modifier=mask_modifier,\n",
    "                            box_expander=box_expander)\n",
    "            score, plots = score_frame_lookup(frame_lookup, chips)\n",
    "            visualizations.extend(plots)\n",
    "            score_strings.append([kernel_size, threshold, chipping_method, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Location: /datasets/texas_dot/Ending20160903/user/*.mp4\n",
      "Camera Name: IH10_Martin\n",
      "Input Mask: False\n",
      "Box Expander: False\n",
      "[Kernel, Threshold, Chipping Method, Score]\n",
      "(9, 9), 4, Methods.OPENCV: 0.49292362082241353\n",
      "(9, 9), 6, Methods.OPENCV: 0.49082251696370893\n",
      "(11, 11), 6, Methods.OPENCV: 0.4906139308344932\n",
      "(11, 11), 4, Methods.OPENCV: 0.48512228085112696\n",
      "(11, 11), 8, Methods.OPENCV: 0.48397767725140955\n",
      "(5, 5), 2, Methods.OPENCV: 0.48310739787825785\n",
      "(9, 9), 2, Methods.OPENCV: 0.4811673714624358\n",
      "(15, 15), 6, Methods.OPENCV: 0.4800441441760739\n",
      "(15, 15), 8, Methods.OPENCV: 0.47229367775426506\n",
      "(11, 11), 2, Methods.OPENCV: 0.4686243078555041\n"
     ]
    }
   ],
   "source": [
    "# Print out top n results from chipping scores\n",
    "print(\"Video Location:\",video_location)\n",
    "print(\"Camera Name:\",camera_name)\n",
    "print(\"Input Mask:\",apply_input_mask)\n",
    "print(\"Box Expander:\",apply_box_expander)\n",
    "print(\"[Kernel, Threshold, Chipping Method, Score]\")\n",
    "for result in sorted(score_strings, key=lambda x: x[3], reverse=True)[:topn]:\n",
    "   print('{}, {}, {}: {}'.format(result[0],result[1],result[2],result[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no plots because 'retain_visualizations' is False\n"
     ]
    }
   ],
   "source": [
    "# Execute cell repeatedly to cycle through frame plots\n",
    "if retain_visualizations:\n",
    "    try:\n",
    "        index+=1\n",
    "        plt.imshow(visualizations[index])\n",
    "    except:\n",
    "        index=0\n",
    "        if len(visualizations): plt.imshow(visualizations[index])\n",
    "else:\n",
    "    print(\"There are no plots because 'retain_visualizations' is\", retain_visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Location: /datasets/texas_dot/Ending20160903/user/*.mp4\n",
      "Camera Name: IH10_Martin\n",
      "Input Mask: False\n",
      "Box Expander: False\n",
      "[Kernel, Threshold, Chipping Method, Score]\n",
      "(5, 5), 2, Methods.BACKGROUND_SUB: 0.022396602204211465\n",
      "(5, 5), 2, Methods.OPENCV: 0.48310739787825785\n",
      "(5, 5), 4, Methods.BACKGROUND_SUB: 0.23852662814505324\n",
      "(5, 5), 4, Methods.OPENCV: 0.4312071395481312\n",
      "(5, 5), 6, Methods.BACKGROUND_SUB: 0.36563493078316023\n",
      "(5, 5), 6, Methods.OPENCV: 0.41660533034859\n",
      "(5, 5), 8, Methods.BACKGROUND_SUB: 0.38552925156310425\n",
      "(5, 5), 8, Methods.OPENCV: 0.38974509471494284\n",
      "(5, 5), 10, Methods.BACKGROUND_SUB: 0.37016902398817403\n",
      "(5, 5), 10, Methods.OPENCV: 0.37725362124123063\n",
      "(5, 5), 12, Methods.BACKGROUND_SUB: 0.3563109153717948\n",
      "(5, 5), 12, Methods.OPENCV: 0.3552908418972148\n",
      "(5, 5), 15, Methods.BACKGROUND_SUB: 0.3371846098110606\n",
      "(5, 5), 15, Methods.OPENCV: 0.3177241766756718\n",
      "(5, 5), 17, Methods.BACKGROUND_SUB: 0.3220181682957436\n",
      "(5, 5), 17, Methods.OPENCV: 0.2988214291093638\n",
      "(5, 5), 20, Methods.BACKGROUND_SUB: 0.30819072739414616\n",
      "(5, 5), 20, Methods.OPENCV: 0.2851579989403853\n",
      "(5, 5), 27, Methods.BACKGROUND_SUB: 0.27345713850032854\n",
      "(5, 5), 27, Methods.OPENCV: 0.23461046956956916\n",
      "(5, 5), 33, Methods.BACKGROUND_SUB: 0.23906837803813755\n",
      "(5, 5), 33, Methods.OPENCV: 0.209703415707466\n",
      "(5, 5), 40, Methods.BACKGROUND_SUB: 0.20534765372295471\n",
      "(5, 5), 40, Methods.OPENCV: 0.18182425248585393\n",
      "(5, 5), 50, Methods.BACKGROUND_SUB: 0.15621798368598444\n",
      "(5, 5), 50, Methods.OPENCV: 0.17202582723313017\n",
      "(9, 9), 2, Methods.BACKGROUND_SUB: 0.019334505136154142\n",
      "(9, 9), 2, Methods.OPENCV: 0.4811673714624358\n",
      "(9, 9), 4, Methods.BACKGROUND_SUB: 0.2310231512883723\n",
      "(9, 9), 4, Methods.OPENCV: 0.49292362082241353\n",
      "(9, 9), 6, Methods.BACKGROUND_SUB: 0.3774995817757803\n",
      "(9, 9), 6, Methods.OPENCV: 0.49082251696370893\n",
      "(9, 9), 8, Methods.BACKGROUND_SUB: 0.40607743948335673\n",
      "(9, 9), 8, Methods.OPENCV: 0.45604136522737687\n",
      "(9, 9), 10, Methods.BACKGROUND_SUB: 0.40385049017089314\n",
      "(9, 9), 10, Methods.OPENCV: 0.43672001893276047\n",
      "(9, 9), 12, Methods.BACKGROUND_SUB: 0.4035240570944955\n",
      "(9, 9), 12, Methods.OPENCV: 0.40865517069995033\n",
      "(9, 9), 15, Methods.BACKGROUND_SUB: 0.37951612541835755\n",
      "(9, 9), 15, Methods.OPENCV: 0.37006216367469374\n",
      "(9, 9), 17, Methods.BACKGROUND_SUB: 0.364866896250259\n",
      "(9, 9), 17, Methods.OPENCV: 0.3508273491454835\n",
      "(9, 9), 20, Methods.BACKGROUND_SUB: 0.339742460370142\n",
      "(9, 9), 20, Methods.OPENCV: 0.3139684643447213\n",
      "(9, 9), 27, Methods.BACKGROUND_SUB: 0.2902686483352778\n",
      "(9, 9), 27, Methods.OPENCV: 0.256833128061062\n",
      "(9, 9), 33, Methods.BACKGROUND_SUB: 0.24680698348221863\n",
      "(9, 9), 33, Methods.OPENCV: 0.23082771335244268\n",
      "(9, 9), 40, Methods.BACKGROUND_SUB: 0.20285314557216122\n",
      "(9, 9), 40, Methods.OPENCV: 0.19628643372548407\n",
      "(9, 9), 50, Methods.BACKGROUND_SUB: 0.15096128897683056\n",
      "(9, 9), 50, Methods.OPENCV: 0.1710676779234447\n",
      "(11, 11), 2, Methods.BACKGROUND_SUB: 0.021472891352310987\n",
      "(11, 11), 2, Methods.OPENCV: 0.4686243078555041\n",
      "(11, 11), 4, Methods.BACKGROUND_SUB: 0.23716976988768448\n",
      "(11, 11), 4, Methods.OPENCV: 0.48512228085112696\n",
      "(11, 11), 6, Methods.BACKGROUND_SUB: 0.37052617214277783\n",
      "(11, 11), 6, Methods.OPENCV: 0.4906139308344932\n",
      "(11, 11), 8, Methods.BACKGROUND_SUB: 0.4101416500619346\n",
      "(11, 11), 8, Methods.OPENCV: 0.48397767725140955\n",
      "(11, 11), 10, Methods.BACKGROUND_SUB: 0.41294549901170474\n",
      "(11, 11), 10, Methods.OPENCV: 0.4453782662953094\n",
      "(11, 11), 12, Methods.BACKGROUND_SUB: 0.41089464558316857\n",
      "(11, 11), 12, Methods.OPENCV: 0.42751107016943624\n",
      "(11, 11), 15, Methods.BACKGROUND_SUB: 0.39040744657085497\n",
      "(11, 11), 15, Methods.OPENCV: 0.3796456907017025\n",
      "(11, 11), 17, Methods.BACKGROUND_SUB: 0.37810759792587645\n",
      "(11, 11), 17, Methods.OPENCV: 0.3582023640008799\n",
      "(11, 11), 20, Methods.BACKGROUND_SUB: 0.34896711832807537\n",
      "(11, 11), 20, Methods.OPENCV: 0.32493356784648136\n",
      "(11, 11), 27, Methods.BACKGROUND_SUB: 0.2881146043978836\n",
      "(11, 11), 27, Methods.OPENCV: 0.2625616723331791\n",
      "(11, 11), 33, Methods.BACKGROUND_SUB: 0.24772616769462563\n",
      "(11, 11), 33, Methods.OPENCV: 0.23157487549271857\n",
      "(11, 11), 40, Methods.BACKGROUND_SUB: 0.19093340465155526\n",
      "(11, 11), 40, Methods.OPENCV: 0.1978002527189965\n",
      "(11, 11), 50, Methods.BACKGROUND_SUB: 0.14429130785799973\n",
      "(11, 11), 50, Methods.OPENCV: 0.17309966856665152\n",
      "(15, 15), 2, Methods.BACKGROUND_SUB: 0.02127752944635246\n",
      "(15, 15), 2, Methods.OPENCV: 0.42404157319102603\n",
      "(15, 15), 4, Methods.BACKGROUND_SUB: 0.22019403537546653\n",
      "(15, 15), 4, Methods.OPENCV: 0.4560874921567325\n",
      "(15, 15), 6, Methods.BACKGROUND_SUB: 0.3412745694507095\n",
      "(15, 15), 6, Methods.OPENCV: 0.4800441441760739\n",
      "(15, 15), 8, Methods.BACKGROUND_SUB: 0.38590177767660394\n",
      "(15, 15), 8, Methods.OPENCV: 0.47229367775426506\n",
      "(15, 15), 10, Methods.BACKGROUND_SUB: 0.4085516948907274\n",
      "(15, 15), 10, Methods.OPENCV: 0.4528666678472509\n",
      "(15, 15), 12, Methods.BACKGROUND_SUB: 0.42081727389934603\n",
      "(15, 15), 12, Methods.OPENCV: 0.4341225703295193\n",
      "(15, 15), 15, Methods.BACKGROUND_SUB: 0.4098369952922712\n",
      "(15, 15), 15, Methods.OPENCV: 0.39725707486244627\n",
      "(15, 15), 17, Methods.BACKGROUND_SUB: 0.3862983958864074\n",
      "(15, 15), 17, Methods.OPENCV: 0.37979121715536396\n",
      "(15, 15), 20, Methods.BACKGROUND_SUB: 0.35981853427719923\n",
      "(15, 15), 20, Methods.OPENCV: 0.3455374549678827\n",
      "(15, 15), 27, Methods.BACKGROUND_SUB: 0.286381612588668\n",
      "(15, 15), 27, Methods.OPENCV: 0.27336606230224225\n",
      "(15, 15), 33, Methods.BACKGROUND_SUB: 0.23478813892785513\n",
      "(15, 15), 33, Methods.OPENCV: 0.23147890005330374\n",
      "(15, 15), 40, Methods.BACKGROUND_SUB: 0.17924622200001966\n",
      "(15, 15), 40, Methods.OPENCV: 0.20412378170812148\n",
      "(15, 15), 50, Methods.BACKGROUND_SUB: 0.1283703914988852\n",
      "(15, 15), 50, Methods.OPENCV: 0.17337571404832566\n",
      "(21, 21), 2, Methods.BACKGROUND_SUB: 0.02002707717869965\n",
      "(21, 21), 2, Methods.OPENCV: 0.3614387997868511\n",
      "(21, 21), 4, Methods.BACKGROUND_SUB: 0.1833584333829764\n",
      "(21, 21), 4, Methods.OPENCV: 0.4253651928838405\n",
      "(21, 21), 6, Methods.BACKGROUND_SUB: 0.2889840648181576\n",
      "(21, 21), 6, Methods.OPENCV: 0.43969123390036996\n",
      "(21, 21), 8, Methods.BACKGROUND_SUB: 0.3576465544036091\n",
      "(21, 21), 8, Methods.OPENCV: 0.45194448794968317\n",
      "(21, 21), 10, Methods.BACKGROUND_SUB: 0.3910253939960085\n",
      "(21, 21), 10, Methods.OPENCV: 0.4437568808722926\n",
      "(21, 21), 12, Methods.BACKGROUND_SUB: 0.40573938610271765\n",
      "(21, 21), 12, Methods.OPENCV: 0.42075798718916685\n",
      "(21, 21), 15, Methods.BACKGROUND_SUB: 0.42100744647195476\n",
      "(21, 21), 15, Methods.OPENCV: 0.38888050129071605\n",
      "(21, 21), 17, Methods.BACKGROUND_SUB: 0.39470430283309765\n",
      "(21, 21), 17, Methods.OPENCV: 0.3745340505298902\n",
      "(21, 21), 20, Methods.BACKGROUND_SUB: 0.36910429996909994\n",
      "(21, 21), 20, Methods.OPENCV: 0.3368923825062753\n",
      "(21, 21), 27, Methods.BACKGROUND_SUB: 0.2801061164220631\n",
      "(21, 21), 27, Methods.OPENCV: 0.2792178701109869\n",
      "(21, 21), 33, Methods.BACKGROUND_SUB: 0.21752121558226278\n",
      "(21, 21), 33, Methods.OPENCV: 0.2318448234957348\n",
      "(21, 21), 40, Methods.BACKGROUND_SUB: 0.16392456427588717\n",
      "(21, 21), 40, Methods.OPENCV: 0.2047061041589204\n",
      "(21, 21), 50, Methods.BACKGROUND_SUB: 0.11092589465752174\n",
      "(21, 21), 50, Methods.OPENCV: 0.17213999293673982\n",
      "(29, 29), 2, Methods.BACKGROUND_SUB: 0.023236790362608093\n",
      "(29, 29), 2, Methods.OPENCV: 0.28782920236060555\n",
      "(29, 29), 4, Methods.BACKGROUND_SUB: 0.1571867314108141\n",
      "(29, 29), 4, Methods.OPENCV: 0.3706588613391145\n",
      "(29, 29), 6, Methods.BACKGROUND_SUB: 0.24368181905390554\n",
      "(29, 29), 6, Methods.OPENCV: 0.4048290926875336\n",
      "(29, 29), 8, Methods.BACKGROUND_SUB: 0.3199168559571573\n",
      "(29, 29), 8, Methods.OPENCV: 0.41298161815127765\n",
      "(29, 29), 10, Methods.BACKGROUND_SUB: 0.37129850420187505\n",
      "(29, 29), 10, Methods.OPENCV: 0.39677075747694085\n",
      "(29, 29), 12, Methods.BACKGROUND_SUB: 0.3952614438224245\n",
      "(29, 29), 12, Methods.OPENCV: 0.38055892536673014\n",
      "(29, 29), 15, Methods.BACKGROUND_SUB: 0.39628681943804916\n",
      "(29, 29), 15, Methods.OPENCV: 0.3570197819910499\n",
      "(29, 29), 17, Methods.BACKGROUND_SUB: 0.37742376255501026\n",
      "(29, 29), 17, Methods.OPENCV: 0.34260215049887033\n",
      "(29, 29), 20, Methods.BACKGROUND_SUB: 0.34470559739586576\n",
      "(29, 29), 20, Methods.OPENCV: 0.3123971890900278\n",
      "(29, 29), 27, Methods.BACKGROUND_SUB: 0.2474915297399216\n",
      "(29, 29), 27, Methods.OPENCV: 0.2545337198432513\n",
      "(29, 29), 33, Methods.BACKGROUND_SUB: 0.17839710178223353\n",
      "(29, 29), 33, Methods.OPENCV: 0.2246557658002747\n",
      "(29, 29), 40, Methods.BACKGROUND_SUB: 0.1341212036865474\n",
      "(29, 29), 40, Methods.OPENCV: 0.18967417091384917\n",
      "(29, 29), 50, Methods.BACKGROUND_SUB: 0.09511942528222785\n",
      "(29, 29), 50, Methods.OPENCV: 0.1704873992639485\n",
      "(33, 33), 2, Methods.BACKGROUND_SUB: 0.02166590327834112\n",
      "(33, 33), 2, Methods.OPENCV: 0.2522254858589894\n",
      "(33, 33), 4, Methods.BACKGROUND_SUB: 0.13786711775662955\n",
      "(33, 33), 4, Methods.OPENCV: 0.33751701782753185\n",
      "(33, 33), 6, Methods.BACKGROUND_SUB: 0.2197482887527168\n",
      "(33, 33), 6, Methods.OPENCV: 0.3752923397022104\n",
      "(33, 33), 8, Methods.BACKGROUND_SUB: 0.29328679946929853\n",
      "(33, 33), 8, Methods.OPENCV: 0.38276024893351085\n",
      "(33, 33), 10, Methods.BACKGROUND_SUB: 0.3451445629628079\n",
      "(33, 33), 10, Methods.OPENCV: 0.37524473044548\n",
      "(33, 33), 12, Methods.BACKGROUND_SUB: 0.37764197636527574\n",
      "(33, 33), 12, Methods.OPENCV: 0.3607250682599311\n",
      "(33, 33), 15, Methods.BACKGROUND_SUB: 0.3810544730900391\n",
      "(33, 33), 15, Methods.OPENCV: 0.34217872106637376\n",
      "(33, 33), 17, Methods.BACKGROUND_SUB: 0.3656463790796288\n",
      "(33, 33), 17, Methods.OPENCV: 0.32235315717877316\n",
      "(33, 33), 20, Methods.BACKGROUND_SUB: 0.3242090926997229\n",
      "(33, 33), 20, Methods.OPENCV: 0.2981682912478518\n",
      "(33, 33), 27, Methods.BACKGROUND_SUB: 0.230575050151101\n",
      "(33, 33), 27, Methods.OPENCV: 0.24223076421383352\n",
      "(33, 33), 33, Methods.BACKGROUND_SUB: 0.1674745035276713\n",
      "(33, 33), 33, Methods.OPENCV: 0.21196423209671678\n",
      "(33, 33), 40, Methods.BACKGROUND_SUB: 0.12639286772751487\n",
      "(33, 33), 40, Methods.OPENCV: 0.18582281519690363\n",
      "(33, 33), 50, Methods.BACKGROUND_SUB: 0.08891213888984505\n",
      "(33, 33), 50, Methods.OPENCV: 0.16824047918585655\n"
     ]
    }
   ],
   "source": [
    "# Full experiment results\n",
    "print(\"Video Location:\",video_location)\n",
    "print(\"Camera Name:\",camera_name)\n",
    "print(\"Input Mask:\",apply_input_mask)\n",
    "print(\"Box Expander:\",apply_box_expander)\n",
    "print(\"[Kernel, Threshold, Chipping Method, Score]\")\n",
    "for line in score_strings: \n",
    "    print('{}, {}, {}: {}'.format(line[0],line[1],line[2],line[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

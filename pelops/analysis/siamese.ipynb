{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Lambda\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pelops.datasets.featuredataset import FeatureDataset\n",
    "from pelops.datasets.veri import VeriDataset\n",
    "from pelops.experiment_api.experiment import ExperimentGenerator\n",
    "from pelops.analysis import analysis\n",
    "from pelops.analysis.camerautil import get_match_id, make_good_bad\n",
    "import pelops.utils as utils\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import queue\n",
    "import threading\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a GPU session and reserve memory\n",
    "def get_session(gpu_fraction=0.3):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "# load an image from disk\n",
    "def load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# use an image with a model to get features\n",
    "def image_features(img, model, length=2048):\n",
    "    features = np.zeros((1, length), dtype=np.float16)\n",
    "    #model = Model(input=base_model.input, output=base_model.get_layer('flatten_1').output)\n",
    "    predictions = model.predict(img)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model_workaround(model, model_output_file, weights_output_file):\n",
    "    print('saving model   to {}'.format(model_output_file))\n",
    "    print('saving weignts to {}'.format(weights_output_file))\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_output_file, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(weights_output_file)\n",
    "\n",
    "\n",
    "def load_model_workaround(model_output_file, weights_output_file):\n",
    "    # load json and create model\n",
    "    json_file = open(model_output_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weights_output_file)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    #dont be stupid and use the wrong axis..\n",
    "    # return K.sqrt(K.sum(K.square(x - y), axis=3, keepdims=True))\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=3, keepdims=False))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def compute_accuracy(predictions, labels, threshold=0.5):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < threshold].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_examples(gen,examples):\n",
    "    left = list()\n",
    "    right = list()\n",
    "    truth = list()\n",
    "    \n",
    "    for _ in range(examples):\n",
    "        cameras = gen.generate()\n",
    "        match_id = get_match_id(cameras)\n",
    "        goods, bads = make_good_bad(cameras,match_id)\n",
    "        left.append(goods[0])\n",
    "        right.append(goods[1])\n",
    "        left.append(bads[0])\n",
    "        right.append(bads[1])\n",
    "        truth.append(True)\n",
    "        truth.append(False)\n",
    "    return(left,right,truth)\n",
    "\n",
    "def examples_2_images(left,right):\n",
    "    length = len(left)\n",
    "    left_images = np.zeros((length,299,299,3))\n",
    "    right_images = np.zeros((length,299,299,3))\n",
    "    for idx,work in enumerate(left):\n",
    "        filename = work.filepath\n",
    "        left_images[idx] = load_image(filename)\n",
    "    for idx,work in enumerate(right):\n",
    "        filename = work.filepath\n",
    "        right_images[idx] = load_image(filename)\n",
    "    return left_images, right_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do the keras setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KTF.set_session(get_session(.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_left = Input(shape=(299, 299, 3))\n",
    "input_right = Input(shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_left = base_model(input_left)\n",
    "processed_right = base_model(input_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_left, \n",
    "                                                        processed_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([input_left, input_right], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get ready to make data and try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set some constants\n",
    "ITEMSPERCAMERA = 2\n",
    "YRANDOM=1024\n",
    "CAMERAS=2\n",
    "DROPPED=0\n",
    "CMC=100\n",
    "EXPERIMENTS=4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "veri_validate = VeriDataset('/local_data/dgrossman/VeRi',set_type=utils.SetType.TEST.value)\n",
    "veri_train = VeriDataset('/local_data/dgrossman/VeRi',set_type = utils.SetType.TRAIN.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expGen_validate = ExperimentGenerator(veri_validate, CAMERAS, ITEMSPERCAMERA, DROPPED, YRANDOM)\n",
    "expGen_train = ExperimentGenerator(veri_train, CAMERAS, ITEMSPERCAMERA, DROPPED, YRANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_train,right_train,truth_train = make_examples(expGen_train,EXPERIMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_validate,right_validate,truth_validate = make_examples(expGen_validate,EXPERIMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_images_train, right_images_train = examples_2_images(left_train,right_train)\n",
    "left_images_validate, right_images_validate = examples_2_images(left_validate,right_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "full_history = model.fit([left_images_train, right_images_train], np.array(truth_train),\n",
    "                         validation_data=([left_images_validate, right_images_validate], np.array(truth_validate)),\n",
    "                         batch_size=16,\n",
    "                         epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

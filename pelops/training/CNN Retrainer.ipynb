{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "def get_session(gpu_fraction=0.3):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import datetime\n",
    "import enum\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential                              \n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Reshape            \n",
    "from keras.preprocessing import image\n",
    "\n",
    "import pelops.const as const\n",
    "from pelops.datasets.dgcars import DGCarsDataset\n",
    "from pelops.utils import SetType, setup_custom_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir_path = \"./datasets/train/\" \n",
    "val_dir_path = \"./datasets/test/\"\n",
    "train_features_path = None\n",
    "val_features_path = None\n",
    "dataset_type = \"DGCarsDataset\"\n",
    "conv_model_type = \"ResNet50\"\n",
    "conv_model_name = \"ResNet50\"\n",
    "\n",
    "nb_epoch = 10\n",
    "dropout_rate = 0.5\n",
    "batch_size = 32\n",
    "seed = 11\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_dimension = 3\n",
    "index_accuracy = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 194 images belonging to 3 classes.\n",
      "Found 151 images belonging to 3 classes.\n",
      "number of classes: 3\n",
      "number of images for training: 194\n",
      "shape of train x: (32, 224, 224, 3), y: (32, 3)\n",
      "number of images for validation: 151\n"
     ]
    }
   ],
   "source": [
    "train_datagen = image.ImageDataGenerator()\n",
    "val_datagen = image.ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    seed=seed, \n",
    "    follow_links=True\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory=val_dir_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    seed=seed,\n",
    "    follow_links=True\n",
    ")\n",
    "\n",
    "print(\"number of classes: {}\".format(train_generator.nb_class))\n",
    "\n",
    "print(\"number of images for training: {}\".format(train_generator.nb_sample))\n",
    "for i in train_generator:\n",
    "    x, y = i\n",
    "    print(\"shape of train x: {}, y: {}\".format(x.shape, y.shape))\n",
    "    break\n",
    "\n",
    "# assumption: 151 images, therefore generator will output 32 * 151 images? \n",
    "print(\"number of images for validation: {}\".format(val_generator.nb_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=Input(\n",
    "                shape=(\n",
    "                    img_height, \n",
    "                    img_width, \n",
    "                    img_dimension\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __extract_features(generator, model, batch_size, set_type):\n",
    "    feature_dirpath = \"./features/\"\n",
    "    print(\"create a feature directory to store saved features: {}\".format(feature_dirpath))\n",
    "    if not os.path.exists(feature_dirpath):\n",
    "        os.makedirs(feature_dirpath)\n",
    "\n",
    "    print(\"extract features from convolutional model based on data\")\n",
    "    print(\"generator: {}_generator\".format(set_type))\n",
    "    print(\"batch_size: {}\".format(batch_size))\n",
    "    features = model.predict_generator(\n",
    "        generator,\n",
    "        batch_size\n",
    "    )\n",
    "\n",
    "    time_now = datetime.datetime.now().strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "    features_filepath = feature_dirpath + \"REALDEAL_{}_{}_{}_features_{}.npy\".format(\n",
    "        dataset_type,\n",
    "        conv_model_type,\n",
    "        set_type,\n",
    "        time_now\n",
    "    )\n",
    "    print(\"save features to {}\".format(features_filepath))\n",
    "    np.save(open(features_filepath, \"wb\"), features)\n",
    "\n",
    "    return features, features_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a feature directory to store saved features: ./features/\n",
      "extract features from convolutional model based on data\n",
      "generator: train_generator\n",
      "batch_size: 32\n",
      "save features to ./features/REALDEAL_DGCarsDataset_ResNet50_train_features_20170216_19_59_28.npy\n"
     ]
    }
   ],
   "source": [
    "train_features, train_features_path = __extract_features(train_generator, model, batch_size, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save features to ./features/REALDEAL_DGCarsDataset_ResNet50_train_features_20170214_23_34_31.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature_path = \"./features/REALDEAL_DGCarsDataset_ResNet50_train_features_20170214_23_34_31.npy\"\n",
    "train_features = np.load(open(train_feature_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train classifier based on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a checkpoint directory to store saved checkpoints: ./checkpoints/\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dirpath = \"./checkpoints/\"\n",
    "print(\"create a checkpoint directory to store saved checkpoints: {}\".format(checkpoint_dirpath))\n",
    "if not os.path.exists(checkpoint_dirpath):\n",
    "    os.makedirs(checkpoint_dirpath)\n",
    "\n",
    "checkpoint_filepath = \\\n",
    "    checkpoint_dirpath + \\\n",
    "    \"{}_{}_features_\".format(dataset_type, \"classifier\") + \\\n",
    "    \"{epoch:02d}_{val_acc:.8f}.npy\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_filepath, \n",
    "    monitor=\"val_acc\", \n",
    "    save_best_only=True, \n",
    "    mode=\"max\"\n",
    ")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 -> [hidden layer 1026] -> 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_classes = train_generator.nb_class\n",
    "nb_features = model.output_shape[-1] # same as train_features.shape[-1]\n",
    "nb_hidden_layers = int(round(np.mean([nb_features, nb_classes])))\n",
    "print(\"{} -> [hidden layer {}] -> {}\\n\".format(nb_features, nb_hidden_layers, nb_classes))\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Dense(nb_hidden_layers, activation=\"relu\", input_shape=train_features.shape[1:]))\n",
    "top_model.add(Flatten())\n",
    "top_model.add(Dense(nb_classes, activation=\"softmax\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1, x.shape: (32, 224, 224, 3), y.shape: (32, 3)\n",
      "y: [[ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in train_generator:\n",
    "    x, y = i\n",
    "    count = count + 1\n",
    "    print(\"count: {}, x.shape: {}, y.shape: {}\".format(count, x.shape, y.shape))\n",
    "    print(\"y: {}\".format(y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1, x.shape: (1, 1, 2048)\n",
      "count: 2, x.shape: (1, 1, 2048)\n",
      "count: 3, x.shape: (1, 1, 2048)\n",
      "count: 4, x.shape: (1, 1, 2048)\n",
      "count: 5, x.shape: (1, 1, 2048)\n",
      "count: 6, x.shape: (1, 1, 2048)\n",
      "count: 7, x.shape: (1, 1, 2048)\n",
      "count: 8, x.shape: (1, 1, 2048)\n",
      "count: 9, x.shape: (1, 1, 2048)\n",
      "count: 10, x.shape: (1, 1, 2048)\n",
      "count: 11, x.shape: (1, 1, 2048)\n",
      "count: 12, x.shape: (1, 1, 2048)\n",
      "count: 13, x.shape: (1, 1, 2048)\n",
      "count: 14, x.shape: (1, 1, 2048)\n",
      "count: 15, x.shape: (1, 1, 2048)\n",
      "count: 16, x.shape: (1, 1, 2048)\n",
      "count: 17, x.shape: (1, 1, 2048)\n",
      "count: 18, x.shape: (1, 1, 2048)\n",
      "count: 19, x.shape: (1, 1, 2048)\n",
      "count: 20, x.shape: (1, 1, 2048)\n",
      "count: 21, x.shape: (1, 1, 2048)\n",
      "count: 22, x.shape: (1, 1, 2048)\n",
      "count: 23, x.shape: (1, 1, 2048)\n",
      "count: 24, x.shape: (1, 1, 2048)\n",
      "count: 25, x.shape: (1, 1, 2048)\n",
      "count: 26, x.shape: (1, 1, 2048)\n",
      "count: 27, x.shape: (1, 1, 2048)\n",
      "count: 28, x.shape: (1, 1, 2048)\n",
      "count: 29, x.shape: (1, 1, 2048)\n",
      "count: 30, x.shape: (1, 1, 2048)\n",
      "count: 31, x.shape: (1, 1, 2048)\n",
      "count: 32, x.shape: (1, 1, 2048)\n",
      "count: 33, x.shape: (1, 1, 2048)\n",
      "count: 34, x.shape: (1, 1, 2048)\n",
      "count: 35, x.shape: (1, 1, 2048)\n",
      "count: 36, x.shape: (1, 1, 2048)\n",
      "count: 37, x.shape: (1, 1, 2048)\n",
      "count: 38, x.shape: (1, 1, 2048)\n",
      "count: 39, x.shape: (1, 1, 2048)\n",
      "count: 40, x.shape: (1, 1, 2048)\n",
      "count: 41, x.shape: (1, 1, 2048)\n",
      "count: 42, x.shape: (1, 1, 2048)\n",
      "count: 43, x.shape: (1, 1, 2048)\n",
      "count: 44, x.shape: (1, 1, 2048)\n",
      "count: 45, x.shape: (1, 1, 2048)\n",
      "count: 46, x.shape: (1, 1, 2048)\n",
      "count: 47, x.shape: (1, 1, 2048)\n",
      "count: 48, x.shape: (1, 1, 2048)\n",
      "count: 49, x.shape: (1, 1, 2048)\n",
      "count: 50, x.shape: (1, 1, 2048)\n",
      "count: 51, x.shape: (1, 1, 2048)\n",
      "count: 52, x.shape: (1, 1, 2048)\n",
      "count: 53, x.shape: (1, 1, 2048)\n",
      "count: 54, x.shape: (1, 1, 2048)\n",
      "count: 55, x.shape: (1, 1, 2048)\n",
      "count: 56, x.shape: (1, 1, 2048)\n",
      "count: 57, x.shape: (1, 1, 2048)\n",
      "count: 58, x.shape: (1, 1, 2048)\n",
      "count: 59, x.shape: (1, 1, 2048)\n",
      "count: 60, x.shape: (1, 1, 2048)\n",
      "count: 61, x.shape: (1, 1, 2048)\n",
      "count: 62, x.shape: (1, 1, 2048)\n",
      "count: 63, x.shape: (1, 1, 2048)\n",
      "count: 64, x.shape: (1, 1, 2048)\n",
      "count: 65, x.shape: (1, 1, 2048)\n",
      "count: 66, x.shape: (1, 1, 2048)\n",
      "count: 67, x.shape: (1, 1, 2048)\n",
      "count: 68, x.shape: (1, 1, 2048)\n",
      "count: 69, x.shape: (1, 1, 2048)\n",
      "count: 70, x.shape: (1, 1, 2048)\n",
      "count: 71, x.shape: (1, 1, 2048)\n",
      "count: 72, x.shape: (1, 1, 2048)\n",
      "count: 73, x.shape: (1, 1, 2048)\n",
      "count: 74, x.shape: (1, 1, 2048)\n",
      "count: 75, x.shape: (1, 1, 2048)\n",
      "count: 76, x.shape: (1, 1, 2048)\n",
      "count: 77, x.shape: (1, 1, 2048)\n",
      "count: 78, x.shape: (1, 1, 2048)\n",
      "count: 79, x.shape: (1, 1, 2048)\n",
      "count: 80, x.shape: (1, 1, 2048)\n",
      "count: 81, x.shape: (1, 1, 2048)\n",
      "count: 82, x.shape: (1, 1, 2048)\n",
      "count: 83, x.shape: (1, 1, 2048)\n",
      "count: 84, x.shape: (1, 1, 2048)\n",
      "count: 85, x.shape: (1, 1, 2048)\n",
      "count: 86, x.shape: (1, 1, 2048)\n",
      "count: 87, x.shape: (1, 1, 2048)\n",
      "count: 88, x.shape: (1, 1, 2048)\n",
      "count: 89, x.shape: (1, 1, 2048)\n",
      "count: 90, x.shape: (1, 1, 2048)\n",
      "count: 91, x.shape: (1, 1, 2048)\n",
      "count: 92, x.shape: (1, 1, 2048)\n",
      "count: 93, x.shape: (1, 1, 2048)\n",
      "count: 94, x.shape: (1, 1, 2048)\n",
      "count: 95, x.shape: (1, 1, 2048)\n",
      "count: 96, x.shape: (1, 1, 2048)\n",
      "count: 97, x.shape: (1, 1, 2048)\n",
      "count: 98, x.shape: (1, 1, 2048)\n",
      "count: 99, x.shape: (1, 1, 2048)\n",
      "count: 100, x.shape: (1, 1, 2048)\n",
      "count: 101, x.shape: (1, 1, 2048)\n",
      "count: 102, x.shape: (1, 1, 2048)\n",
      "count: 103, x.shape: (1, 1, 2048)\n",
      "count: 104, x.shape: (1, 1, 2048)\n",
      "count: 105, x.shape: (1, 1, 2048)\n",
      "count: 106, x.shape: (1, 1, 2048)\n",
      "count: 107, x.shape: (1, 1, 2048)\n",
      "count: 108, x.shape: (1, 1, 2048)\n",
      "count: 109, x.shape: (1, 1, 2048)\n",
      "count: 110, x.shape: (1, 1, 2048)\n",
      "count: 111, x.shape: (1, 1, 2048)\n",
      "count: 112, x.shape: (1, 1, 2048)\n",
      "count: 113, x.shape: (1, 1, 2048)\n",
      "count: 114, x.shape: (1, 1, 2048)\n",
      "count: 115, x.shape: (1, 1, 2048)\n",
      "count: 116, x.shape: (1, 1, 2048)\n",
      "count: 117, x.shape: (1, 1, 2048)\n",
      "count: 118, x.shape: (1, 1, 2048)\n",
      "count: 119, x.shape: (1, 1, 2048)\n",
      "count: 120, x.shape: (1, 1, 2048)\n",
      "count: 121, x.shape: (1, 1, 2048)\n",
      "count: 122, x.shape: (1, 1, 2048)\n",
      "count: 123, x.shape: (1, 1, 2048)\n",
      "count: 124, x.shape: (1, 1, 2048)\n",
      "count: 125, x.shape: (1, 1, 2048)\n",
      "count: 126, x.shape: (1, 1, 2048)\n",
      "count: 127, x.shape: (1, 1, 2048)\n",
      "count: 128, x.shape: (1, 1, 2048)\n",
      "count: 129, x.shape: (1, 1, 2048)\n",
      "count: 130, x.shape: (1, 1, 2048)\n",
      "count: 131, x.shape: (1, 1, 2048)\n",
      "count: 132, x.shape: (1, 1, 2048)\n",
      "count: 133, x.shape: (1, 1, 2048)\n",
      "count: 134, x.shape: (1, 1, 2048)\n",
      "count: 135, x.shape: (1, 1, 2048)\n",
      "count: 136, x.shape: (1, 1, 2048)\n",
      "count: 137, x.shape: (1, 1, 2048)\n",
      "count: 138, x.shape: (1, 1, 2048)\n",
      "count: 139, x.shape: (1, 1, 2048)\n",
      "count: 140, x.shape: (1, 1, 2048)\n",
      "count: 141, x.shape: (1, 1, 2048)\n",
      "count: 142, x.shape: (1, 1, 2048)\n",
      "count: 143, x.shape: (1, 1, 2048)\n",
      "count: 144, x.shape: (1, 1, 2048)\n",
      "count: 145, x.shape: (1, 1, 2048)\n",
      "count: 146, x.shape: (1, 1, 2048)\n",
      "count: 147, x.shape: (1, 1, 2048)\n",
      "count: 148, x.shape: (1, 1, 2048)\n",
      "count: 149, x.shape: (1, 1, 2048)\n",
      "count: 150, x.shape: (1, 1, 2048)\n",
      "count: 151, x.shape: (1, 1, 2048)\n",
      "count: 152, x.shape: (1, 1, 2048)\n",
      "count: 153, x.shape: (1, 1, 2048)\n",
      "count: 154, x.shape: (1, 1, 2048)\n",
      "count: 155, x.shape: (1, 1, 2048)\n",
      "count: 156, x.shape: (1, 1, 2048)\n",
      "count: 157, x.shape: (1, 1, 2048)\n",
      "count: 158, x.shape: (1, 1, 2048)\n",
      "count: 159, x.shape: (1, 1, 2048)\n",
      "count: 160, x.shape: (1, 1, 2048)\n",
      "count: 161, x.shape: (1, 1, 2048)\n",
      "count: 162, x.shape: (1, 1, 2048)\n",
      "count: 163, x.shape: (1, 1, 2048)\n",
      "count: 164, x.shape: (1, 1, 2048)\n",
      "count: 165, x.shape: (1, 1, 2048)\n",
      "count: 166, x.shape: (1, 1, 2048)\n",
      "count: 167, x.shape: (1, 1, 2048)\n",
      "count: 168, x.shape: (1, 1, 2048)\n",
      "count: 169, x.shape: (1, 1, 2048)\n",
      "count: 170, x.shape: (1, 1, 2048)\n",
      "count: 171, x.shape: (1, 1, 2048)\n",
      "count: 172, x.shape: (1, 1, 2048)\n",
      "count: 173, x.shape: (1, 1, 2048)\n",
      "count: 174, x.shape: (1, 1, 2048)\n",
      "count: 175, x.shape: (1, 1, 2048)\n",
      "count: 176, x.shape: (1, 1, 2048)\n",
      "count: 177, x.shape: (1, 1, 2048)\n",
      "count: 178, x.shape: (1, 1, 2048)\n",
      "count: 179, x.shape: (1, 1, 2048)\n",
      "count: 180, x.shape: (1, 1, 2048)\n",
      "count: 181, x.shape: (1, 1, 2048)\n",
      "count: 182, x.shape: (1, 1, 2048)\n",
      "count: 183, x.shape: (1, 1, 2048)\n",
      "count: 184, x.shape: (1, 1, 2048)\n",
      "count: 185, x.shape: (1, 1, 2048)\n",
      "count: 186, x.shape: (1, 1, 2048)\n",
      "count: 187, x.shape: (1, 1, 2048)\n",
      "count: 188, x.shape: (1, 1, 2048)\n",
      "count: 189, x.shape: (1, 1, 2048)\n",
      "count: 190, x.shape: (1, 1, 2048)\n",
      "count: 191, x.shape: (1, 1, 2048)\n",
      "count: 192, x.shape: (1, 1, 2048)\n",
      "count: 193, x.shape: (1, 1, 2048)\n",
      "count: 194, x.shape: (1, 1, 2048)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for x in train_features:\n",
    "    count = count + 1\n",
    "    print(\"count: {}, x.shape: {}\".format(count, x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x.shape: (1, 224, 224, 3), y.shape: (1, 3)\n",
    "# batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n",
      "2 1\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "class_dictionary = train_generator.class_indices\n",
    "\n",
    "for key, value in class_dictionary.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1, i: 0\n",
      "count: 2, i: 0\n",
      "count: 3, i: 0\n",
      "count: 4, i: 0\n",
      "count: 5, i: 0\n",
      "count: 6, i: 0\n",
      "count: 7, i: 0\n",
      "count: 8, i: 0\n",
      "count: 9, i: 0\n",
      "count: 10, i: 0\n",
      "count: 11, i: 0\n",
      "count: 12, i: 0\n",
      "count: 13, i: 0\n",
      "count: 14, i: 0\n",
      "count: 15, i: 0\n",
      "count: 16, i: 0\n",
      "count: 17, i: 0\n",
      "count: 18, i: 0\n",
      "count: 19, i: 0\n",
      "count: 20, i: 0\n",
      "count: 21, i: 0\n",
      "count: 22, i: 0\n",
      "count: 23, i: 0\n",
      "count: 24, i: 0\n",
      "count: 25, i: 0\n",
      "count: 26, i: 0\n",
      "count: 27, i: 0\n",
      "count: 28, i: 0\n",
      "count: 29, i: 0\n",
      "count: 30, i: 0\n",
      "count: 31, i: 0\n",
      "count: 32, i: 0\n",
      "count: 33, i: 0\n",
      "count: 34, i: 0\n",
      "count: 35, i: 0\n",
      "count: 36, i: 0\n",
      "count: 37, i: 0\n",
      "count: 38, i: 0\n",
      "count: 39, i: 0\n",
      "count: 40, i: 0\n",
      "count: 41, i: 0\n",
      "count: 42, i: 0\n",
      "count: 43, i: 0\n",
      "count: 44, i: 0\n",
      "count: 45, i: 0\n",
      "count: 46, i: 0\n",
      "count: 47, i: 0\n",
      "count: 48, i: 0\n",
      "count: 49, i: 0\n",
      "count: 50, i: 0\n",
      "count: 51, i: 0\n",
      "count: 52, i: 0\n",
      "count: 53, i: 0\n",
      "count: 54, i: 0\n",
      "count: 55, i: 0\n",
      "count: 56, i: 0\n",
      "count: 57, i: 0\n",
      "count: 58, i: 0\n",
      "count: 59, i: 0\n",
      "count: 60, i: 0\n",
      "count: 61, i: 0\n",
      "count: 62, i: 0\n",
      "count: 63, i: 0\n",
      "count: 64, i: 1\n",
      "count: 65, i: 1\n",
      "count: 66, i: 1\n",
      "count: 67, i: 1\n",
      "count: 68, i: 1\n",
      "count: 69, i: 1\n",
      "count: 70, i: 1\n",
      "count: 71, i: 1\n",
      "count: 72, i: 1\n",
      "count: 73, i: 1\n",
      "count: 74, i: 1\n",
      "count: 75, i: 1\n",
      "count: 76, i: 1\n",
      "count: 77, i: 1\n",
      "count: 78, i: 1\n",
      "count: 79, i: 1\n",
      "count: 80, i: 1\n",
      "count: 81, i: 1\n",
      "count: 82, i: 1\n",
      "count: 83, i: 1\n",
      "count: 84, i: 1\n",
      "count: 85, i: 1\n",
      "count: 86, i: 1\n",
      "count: 87, i: 1\n",
      "count: 88, i: 1\n",
      "count: 89, i: 1\n",
      "count: 90, i: 1\n",
      "count: 91, i: 1\n",
      "count: 92, i: 1\n",
      "count: 93, i: 1\n",
      "count: 94, i: 1\n",
      "count: 95, i: 1\n",
      "count: 96, i: 1\n",
      "count: 97, i: 1\n",
      "count: 98, i: 1\n",
      "count: 99, i: 1\n",
      "count: 100, i: 1\n",
      "count: 101, i: 1\n",
      "count: 102, i: 1\n",
      "count: 103, i: 1\n",
      "count: 104, i: 1\n",
      "count: 105, i: 1\n",
      "count: 106, i: 1\n",
      "count: 107, i: 1\n",
      "count: 108, i: 1\n",
      "count: 109, i: 1\n",
      "count: 110, i: 1\n",
      "count: 111, i: 1\n",
      "count: 112, i: 1\n",
      "count: 113, i: 1\n",
      "count: 114, i: 1\n",
      "count: 115, i: 1\n",
      "count: 116, i: 1\n",
      "count: 117, i: 1\n",
      "count: 118, i: 1\n",
      "count: 119, i: 1\n",
      "count: 120, i: 2\n",
      "count: 121, i: 2\n",
      "count: 122, i: 2\n",
      "count: 123, i: 2\n",
      "count: 124, i: 2\n",
      "count: 125, i: 2\n",
      "count: 126, i: 2\n",
      "count: 127, i: 2\n",
      "count: 128, i: 2\n",
      "count: 129, i: 2\n",
      "count: 130, i: 2\n",
      "count: 131, i: 2\n",
      "count: 132, i: 2\n",
      "count: 133, i: 2\n",
      "count: 134, i: 2\n",
      "count: 135, i: 2\n",
      "count: 136, i: 2\n",
      "count: 137, i: 2\n",
      "count: 138, i: 2\n",
      "count: 139, i: 2\n",
      "count: 140, i: 2\n",
      "count: 141, i: 2\n",
      "count: 142, i: 2\n",
      "count: 143, i: 2\n",
      "count: 144, i: 2\n",
      "count: 145, i: 2\n",
      "count: 146, i: 2\n",
      "count: 147, i: 2\n",
      "count: 148, i: 2\n",
      "count: 149, i: 2\n",
      "count: 150, i: 2\n",
      "count: 151, i: 2\n",
      "count: 152, i: 2\n",
      "count: 153, i: 2\n",
      "count: 154, i: 2\n",
      "count: 155, i: 2\n",
      "count: 156, i: 2\n",
      "count: 157, i: 2\n",
      "count: 158, i: 2\n",
      "count: 159, i: 2\n",
      "count: 160, i: 2\n",
      "count: 161, i: 2\n",
      "count: 162, i: 2\n",
      "count: 163, i: 2\n",
      "count: 164, i: 2\n",
      "count: 165, i: 2\n",
      "count: 166, i: 2\n",
      "count: 167, i: 2\n",
      "count: 168, i: 2\n",
      "count: 169, i: 2\n",
      "count: 170, i: 2\n",
      "count: 171, i: 2\n",
      "count: 172, i: 2\n",
      "count: 173, i: 2\n",
      "count: 174, i: 2\n",
      "count: 175, i: 2\n",
      "count: 176, i: 2\n",
      "count: 177, i: 2\n",
      "count: 178, i: 2\n",
      "count: 179, i: 2\n",
      "count: 180, i: 2\n",
      "count: 181, i: 2\n",
      "count: 182, i: 2\n",
      "count: 183, i: 2\n",
      "count: 184, i: 2\n",
      "count: 185, i: 2\n",
      "count: 186, i: 2\n",
      "count: 187, i: 2\n",
      "count: 188, i: 2\n",
      "count: 189, i: 2\n",
      "count: 190, i: 2\n",
      "count: 191, i: 2\n",
      "count: 192, i: 2\n",
      "count: 193, i: 2\n",
      "count: 194, i: 2\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in train_generator.classes:\n",
    "    count = count + 1\n",
    "    print(\"count: {}, i: {}\".format(count, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape: (60000, 10)\n",
      "X_train.shape: (60000, 1, 28, 28)\n",
      "X_train.shape: (60000, 1, 28, 28)\n",
      "X_train.shape: (60000, 1, 28, 28)\n",
      "0\n",
      "count: 0, x.shape: (32, 1, 28, 28), y.shape: (32, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncount = 0\\nfor i in train_feature_generator:\\n    x, y = i\\n    count = count + 1\\n    print(\"count: {}, x.shape: {}, y.shape: {}\".format(count, x.shape, y.shape))\\n    print(\"type of y: {}\".format(type(y)))\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            return self.it.next()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "@threadsafe_generator\n",
    "def __create_generator_from_features(feature, generator):  # write the definition of your data generator\n",
    "    for feature, class_index in zip(features, generator.classes):\n",
    "        label = np.zeros(generator.nb_class)\n",
    "        label[class_index] = 1\n",
    "        yield (feature, label)\n",
    "    \n",
    "    \"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    y_train = np_utils.to_categorical(y_train,10)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    while 1:\n",
    "        for i in range(1875):\n",
    "            yield X_train[i*32:(i+1)*32], y_train[i*32:(i+1)*32]\n",
    "        # print(\"Came here\")\n",
    "    \"\"\"\n",
    "\n",
    "#@threadsafe_generator\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "def mygenerator():  # write the definition of your data generator\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    y_train = np_utils.to_categorical(y_train,10)\n",
    "    print(\"y_train.shape: {}\".format(y_train.shape))\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "    print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "    X_train = X_train.astype('float32')\n",
    "    print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "    X_test /= 255\n",
    "    while 1:\n",
    "        for i in range(1875):\n",
    "            print(i)\n",
    "            yield X_train[i*32:(i+1)*32], y_train[i*32:(i+1)*32]\n",
    "\n",
    "count = 0\n",
    "for i in mygenerator():\n",
    "    x, y = i\n",
    "    print(\"count: {}, x.shape: {}, y.shape: {}\".format(count, x.shape, y.shape))\n",
    "    #print(\">> x: {}\".format(x))\n",
    "    #print(\">> y: {}\".format(y)'break)\n",
    "    break\n",
    "\n",
    "        \n",
    "#train_feature_generator = __create_generator_from_features(train_features, train_generator)\n",
    "\n",
    "\"\"\"\n",
    "count = 0\n",
    "for i in train_feature_generator:\n",
    "    x, y = i\n",
    "    count = count + 1\n",
    "    print(\"count: {}, x.shape: {}, y.shape: {}\".format(count, x.shape, y.shape))\n",
    "    print(\"type of y: {}\".format(type(y)))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1, i: 0, class_index: 0, labels[0]: [ 1.  0.  0.]\n",
      "count: 2, i: 1, class_index: 0, labels[1]: [ 1.  0.  0.]\n",
      "count: 3, i: 2, class_index: 0, labels[2]: [ 1.  0.  0.]\n",
      "count: 4, i: 3, class_index: 0, labels[3]: [ 1.  0.  0.]\n",
      "count: 5, i: 4, class_index: 0, labels[4]: [ 1.  0.  0.]\n",
      "count: 6, i: 5, class_index: 0, labels[5]: [ 1.  0.  0.]\n",
      "count: 7, i: 6, class_index: 0, labels[6]: [ 1.  0.  0.]\n",
      "count: 8, i: 7, class_index: 0, labels[7]: [ 1.  0.  0.]\n",
      "count: 9, i: 8, class_index: 0, labels[8]: [ 1.  0.  0.]\n",
      "count: 10, i: 9, class_index: 0, labels[9]: [ 1.  0.  0.]\n",
      "count: 11, i: 10, class_index: 0, labels[10]: [ 1.  0.  0.]\n",
      "count: 12, i: 11, class_index: 0, labels[11]: [ 1.  0.  0.]\n",
      "count: 13, i: 12, class_index: 0, labels[12]: [ 1.  0.  0.]\n",
      "count: 14, i: 13, class_index: 0, labels[13]: [ 1.  0.  0.]\n",
      "count: 15, i: 14, class_index: 0, labels[14]: [ 1.  0.  0.]\n",
      "count: 16, i: 15, class_index: 0, labels[15]: [ 1.  0.  0.]\n",
      "count: 17, i: 16, class_index: 0, labels[16]: [ 1.  0.  0.]\n",
      "count: 18, i: 17, class_index: 0, labels[17]: [ 1.  0.  0.]\n",
      "count: 19, i: 18, class_index: 0, labels[18]: [ 1.  0.  0.]\n",
      "count: 20, i: 19, class_index: 0, labels[19]: [ 1.  0.  0.]\n",
      "count: 21, i: 20, class_index: 0, labels[20]: [ 1.  0.  0.]\n",
      "count: 22, i: 21, class_index: 0, labels[21]: [ 1.  0.  0.]\n",
      "count: 23, i: 22, class_index: 0, labels[22]: [ 1.  0.  0.]\n",
      "count: 24, i: 23, class_index: 0, labels[23]: [ 1.  0.  0.]\n",
      "count: 25, i: 24, class_index: 0, labels[24]: [ 1.  0.  0.]\n",
      "count: 26, i: 25, class_index: 0, labels[25]: [ 1.  0.  0.]\n",
      "count: 27, i: 26, class_index: 0, labels[26]: [ 1.  0.  0.]\n",
      "count: 28, i: 27, class_index: 0, labels[27]: [ 1.  0.  0.]\n",
      "count: 29, i: 28, class_index: 0, labels[28]: [ 1.  0.  0.]\n",
      "count: 30, i: 29, class_index: 0, labels[29]: [ 1.  0.  0.]\n",
      "count: 31, i: 30, class_index: 0, labels[30]: [ 1.  0.  0.]\n",
      "count: 32, i: 31, class_index: 0, labels[31]: [ 1.  0.  0.]\n",
      "count: 33, i: 32, class_index: 0, labels[32]: [ 1.  0.  0.]\n",
      "count: 34, i: 33, class_index: 0, labels[33]: [ 1.  0.  0.]\n",
      "count: 35, i: 34, class_index: 0, labels[34]: [ 1.  0.  0.]\n",
      "count: 36, i: 35, class_index: 0, labels[35]: [ 1.  0.  0.]\n",
      "count: 37, i: 36, class_index: 0, labels[36]: [ 1.  0.  0.]\n",
      "count: 38, i: 37, class_index: 0, labels[37]: [ 1.  0.  0.]\n",
      "count: 39, i: 38, class_index: 0, labels[38]: [ 1.  0.  0.]\n",
      "count: 40, i: 39, class_index: 0, labels[39]: [ 1.  0.  0.]\n",
      "count: 41, i: 40, class_index: 0, labels[40]: [ 1.  0.  0.]\n",
      "count: 42, i: 41, class_index: 0, labels[41]: [ 1.  0.  0.]\n",
      "count: 43, i: 42, class_index: 0, labels[42]: [ 1.  0.  0.]\n",
      "count: 44, i: 43, class_index: 0, labels[43]: [ 1.  0.  0.]\n",
      "count: 45, i: 44, class_index: 0, labels[44]: [ 1.  0.  0.]\n",
      "count: 46, i: 45, class_index: 0, labels[45]: [ 1.  0.  0.]\n",
      "count: 47, i: 46, class_index: 0, labels[46]: [ 1.  0.  0.]\n",
      "count: 48, i: 47, class_index: 0, labels[47]: [ 1.  0.  0.]\n",
      "count: 49, i: 48, class_index: 0, labels[48]: [ 1.  0.  0.]\n",
      "count: 50, i: 49, class_index: 0, labels[49]: [ 1.  0.  0.]\n",
      "count: 51, i: 50, class_index: 0, labels[50]: [ 1.  0.  0.]\n",
      "count: 52, i: 51, class_index: 0, labels[51]: [ 1.  0.  0.]\n",
      "count: 53, i: 52, class_index: 0, labels[52]: [ 1.  0.  0.]\n",
      "count: 54, i: 53, class_index: 0, labels[53]: [ 1.  0.  0.]\n",
      "count: 55, i: 54, class_index: 0, labels[54]: [ 1.  0.  0.]\n",
      "count: 56, i: 55, class_index: 0, labels[55]: [ 1.  0.  0.]\n",
      "count: 57, i: 56, class_index: 0, labels[56]: [ 1.  0.  0.]\n",
      "count: 58, i: 57, class_index: 0, labels[57]: [ 1.  0.  0.]\n",
      "count: 59, i: 58, class_index: 0, labels[58]: [ 1.  0.  0.]\n",
      "count: 60, i: 59, class_index: 0, labels[59]: [ 1.  0.  0.]\n",
      "count: 61, i: 60, class_index: 0, labels[60]: [ 1.  0.  0.]\n",
      "count: 62, i: 61, class_index: 0, labels[61]: [ 1.  0.  0.]\n",
      "count: 63, i: 62, class_index: 0, labels[62]: [ 1.  0.  0.]\n",
      "count: 64, i: 63, class_index: 1, labels[63]: [ 0.  1.  0.]\n",
      "count: 65, i: 64, class_index: 1, labels[64]: [ 0.  1.  0.]\n",
      "count: 66, i: 65, class_index: 1, labels[65]: [ 0.  1.  0.]\n",
      "count: 67, i: 66, class_index: 1, labels[66]: [ 0.  1.  0.]\n",
      "count: 68, i: 67, class_index: 1, labels[67]: [ 0.  1.  0.]\n",
      "count: 69, i: 68, class_index: 1, labels[68]: [ 0.  1.  0.]\n",
      "count: 70, i: 69, class_index: 1, labels[69]: [ 0.  1.  0.]\n",
      "count: 71, i: 70, class_index: 1, labels[70]: [ 0.  1.  0.]\n",
      "count: 72, i: 71, class_index: 1, labels[71]: [ 0.  1.  0.]\n",
      "count: 73, i: 72, class_index: 1, labels[72]: [ 0.  1.  0.]\n",
      "count: 74, i: 73, class_index: 1, labels[73]: [ 0.  1.  0.]\n",
      "count: 75, i: 74, class_index: 1, labels[74]: [ 0.  1.  0.]\n",
      "count: 76, i: 75, class_index: 1, labels[75]: [ 0.  1.  0.]\n",
      "count: 77, i: 76, class_index: 1, labels[76]: [ 0.  1.  0.]\n",
      "count: 78, i: 77, class_index: 1, labels[77]: [ 0.  1.  0.]\n",
      "count: 79, i: 78, class_index: 1, labels[78]: [ 0.  1.  0.]\n",
      "count: 80, i: 79, class_index: 1, labels[79]: [ 0.  1.  0.]\n",
      "count: 81, i: 80, class_index: 1, labels[80]: [ 0.  1.  0.]\n",
      "count: 82, i: 81, class_index: 1, labels[81]: [ 0.  1.  0.]\n",
      "count: 83, i: 82, class_index: 1, labels[82]: [ 0.  1.  0.]\n",
      "count: 84, i: 83, class_index: 1, labels[83]: [ 0.  1.  0.]\n",
      "count: 85, i: 84, class_index: 1, labels[84]: [ 0.  1.  0.]\n",
      "count: 86, i: 85, class_index: 1, labels[85]: [ 0.  1.  0.]\n",
      "count: 87, i: 86, class_index: 1, labels[86]: [ 0.  1.  0.]\n",
      "count: 88, i: 87, class_index: 1, labels[87]: [ 0.  1.  0.]\n",
      "count: 89, i: 88, class_index: 1, labels[88]: [ 0.  1.  0.]\n",
      "count: 90, i: 89, class_index: 1, labels[89]: [ 0.  1.  0.]\n",
      "count: 91, i: 90, class_index: 1, labels[90]: [ 0.  1.  0.]\n",
      "count: 92, i: 91, class_index: 1, labels[91]: [ 0.  1.  0.]\n",
      "count: 93, i: 92, class_index: 1, labels[92]: [ 0.  1.  0.]\n",
      "count: 94, i: 93, class_index: 1, labels[93]: [ 0.  1.  0.]\n",
      "count: 95, i: 94, class_index: 1, labels[94]: [ 0.  1.  0.]\n",
      "count: 96, i: 95, class_index: 1, labels[95]: [ 0.  1.  0.]\n",
      "count: 97, i: 96, class_index: 1, labels[96]: [ 0.  1.  0.]\n",
      "count: 98, i: 97, class_index: 1, labels[97]: [ 0.  1.  0.]\n",
      "count: 99, i: 98, class_index: 1, labels[98]: [ 0.  1.  0.]\n",
      "count: 100, i: 99, class_index: 1, labels[99]: [ 0.  1.  0.]\n",
      "count: 101, i: 100, class_index: 1, labels[100]: [ 0.  1.  0.]\n",
      "count: 102, i: 101, class_index: 1, labels[101]: [ 0.  1.  0.]\n",
      "count: 103, i: 102, class_index: 1, labels[102]: [ 0.  1.  0.]\n",
      "count: 104, i: 103, class_index: 1, labels[103]: [ 0.  1.  0.]\n",
      "count: 105, i: 104, class_index: 1, labels[104]: [ 0.  1.  0.]\n",
      "count: 106, i: 105, class_index: 1, labels[105]: [ 0.  1.  0.]\n",
      "count: 107, i: 106, class_index: 1, labels[106]: [ 0.  1.  0.]\n",
      "count: 108, i: 107, class_index: 1, labels[107]: [ 0.  1.  0.]\n",
      "count: 109, i: 108, class_index: 1, labels[108]: [ 0.  1.  0.]\n",
      "count: 110, i: 109, class_index: 1, labels[109]: [ 0.  1.  0.]\n",
      "count: 111, i: 110, class_index: 1, labels[110]: [ 0.  1.  0.]\n",
      "count: 112, i: 111, class_index: 1, labels[111]: [ 0.  1.  0.]\n",
      "count: 113, i: 112, class_index: 1, labels[112]: [ 0.  1.  0.]\n",
      "count: 114, i: 113, class_index: 1, labels[113]: [ 0.  1.  0.]\n",
      "count: 115, i: 114, class_index: 1, labels[114]: [ 0.  1.  0.]\n",
      "count: 116, i: 115, class_index: 1, labels[115]: [ 0.  1.  0.]\n",
      "count: 117, i: 116, class_index: 1, labels[116]: [ 0.  1.  0.]\n",
      "count: 118, i: 117, class_index: 1, labels[117]: [ 0.  1.  0.]\n",
      "count: 119, i: 118, class_index: 1, labels[118]: [ 0.  1.  0.]\n",
      "count: 120, i: 119, class_index: 2, labels[119]: [ 0.  0.  1.]\n",
      "count: 121, i: 120, class_index: 2, labels[120]: [ 0.  0.  1.]\n",
      "count: 122, i: 121, class_index: 2, labels[121]: [ 0.  0.  1.]\n",
      "count: 123, i: 122, class_index: 2, labels[122]: [ 0.  0.  1.]\n",
      "count: 124, i: 123, class_index: 2, labels[123]: [ 0.  0.  1.]\n",
      "count: 125, i: 124, class_index: 2, labels[124]: [ 0.  0.  1.]\n",
      "count: 126, i: 125, class_index: 2, labels[125]: [ 0.  0.  1.]\n",
      "count: 127, i: 126, class_index: 2, labels[126]: [ 0.  0.  1.]\n",
      "count: 128, i: 127, class_index: 2, labels[127]: [ 0.  0.  1.]\n",
      "count: 129, i: 128, class_index: 2, labels[128]: [ 0.  0.  1.]\n",
      "count: 130, i: 129, class_index: 2, labels[129]: [ 0.  0.  1.]\n",
      "count: 131, i: 130, class_index: 2, labels[130]: [ 0.  0.  1.]\n",
      "count: 132, i: 131, class_index: 2, labels[131]: [ 0.  0.  1.]\n",
      "count: 133, i: 132, class_index: 2, labels[132]: [ 0.  0.  1.]\n",
      "count: 134, i: 133, class_index: 2, labels[133]: [ 0.  0.  1.]\n",
      "count: 135, i: 134, class_index: 2, labels[134]: [ 0.  0.  1.]\n",
      "count: 136, i: 135, class_index: 2, labels[135]: [ 0.  0.  1.]\n",
      "count: 137, i: 136, class_index: 2, labels[136]: [ 0.  0.  1.]\n",
      "count: 138, i: 137, class_index: 2, labels[137]: [ 0.  0.  1.]\n",
      "count: 139, i: 138, class_index: 2, labels[138]: [ 0.  0.  1.]\n",
      "count: 140, i: 139, class_index: 2, labels[139]: [ 0.  0.  1.]\n",
      "count: 141, i: 140, class_index: 2, labels[140]: [ 0.  0.  1.]\n",
      "count: 142, i: 141, class_index: 2, labels[141]: [ 0.  0.  1.]\n",
      "count: 143, i: 142, class_index: 2, labels[142]: [ 0.  0.  1.]\n",
      "count: 144, i: 143, class_index: 2, labels[143]: [ 0.  0.  1.]\n",
      "count: 145, i: 144, class_index: 2, labels[144]: [ 0.  0.  1.]\n",
      "count: 146, i: 145, class_index: 2, labels[145]: [ 0.  0.  1.]\n",
      "count: 147, i: 146, class_index: 2, labels[146]: [ 0.  0.  1.]\n",
      "count: 148, i: 147, class_index: 2, labels[147]: [ 0.  0.  1.]\n",
      "count: 149, i: 148, class_index: 2, labels[148]: [ 0.  0.  1.]\n",
      "count: 150, i: 149, class_index: 2, labels[149]: [ 0.  0.  1.]\n",
      "count: 151, i: 150, class_index: 2, labels[150]: [ 0.  0.  1.]\n",
      "count: 152, i: 151, class_index: 2, labels[151]: [ 0.  0.  1.]\n",
      "count: 153, i: 152, class_index: 2, labels[152]: [ 0.  0.  1.]\n",
      "count: 154, i: 153, class_index: 2, labels[153]: [ 0.  0.  1.]\n",
      "count: 155, i: 154, class_index: 2, labels[154]: [ 0.  0.  1.]\n",
      "count: 156, i: 155, class_index: 2, labels[155]: [ 0.  0.  1.]\n",
      "count: 157, i: 156, class_index: 2, labels[156]: [ 0.  0.  1.]\n",
      "count: 158, i: 157, class_index: 2, labels[157]: [ 0.  0.  1.]\n",
      "count: 159, i: 158, class_index: 2, labels[158]: [ 0.  0.  1.]\n",
      "count: 160, i: 159, class_index: 2, labels[159]: [ 0.  0.  1.]\n",
      "count: 161, i: 160, class_index: 2, labels[160]: [ 0.  0.  1.]\n",
      "count: 162, i: 161, class_index: 2, labels[161]: [ 0.  0.  1.]\n",
      "count: 163, i: 162, class_index: 2, labels[162]: [ 0.  0.  1.]\n",
      "count: 164, i: 163, class_index: 2, labels[163]: [ 0.  0.  1.]\n",
      "count: 165, i: 164, class_index: 2, labels[164]: [ 0.  0.  1.]\n",
      "count: 166, i: 165, class_index: 2, labels[165]: [ 0.  0.  1.]\n",
      "count: 167, i: 166, class_index: 2, labels[166]: [ 0.  0.  1.]\n",
      "count: 168, i: 167, class_index: 2, labels[167]: [ 0.  0.  1.]\n",
      "count: 169, i: 168, class_index: 2, labels[168]: [ 0.  0.  1.]\n",
      "count: 170, i: 169, class_index: 2, labels[169]: [ 0.  0.  1.]\n",
      "count: 171, i: 170, class_index: 2, labels[170]: [ 0.  0.  1.]\n",
      "count: 172, i: 171, class_index: 2, labels[171]: [ 0.  0.  1.]\n",
      "count: 173, i: 172, class_index: 2, labels[172]: [ 0.  0.  1.]\n",
      "count: 174, i: 173, class_index: 2, labels[173]: [ 0.  0.  1.]\n",
      "count: 175, i: 174, class_index: 2, labels[174]: [ 0.  0.  1.]\n",
      "count: 176, i: 175, class_index: 2, labels[175]: [ 0.  0.  1.]\n",
      "count: 177, i: 176, class_index: 2, labels[176]: [ 0.  0.  1.]\n",
      "count: 178, i: 177, class_index: 2, labels[177]: [ 0.  0.  1.]\n",
      "count: 179, i: 178, class_index: 2, labels[178]: [ 0.  0.  1.]\n",
      "count: 180, i: 179, class_index: 2, labels[179]: [ 0.  0.  1.]\n",
      "count: 181, i: 180, class_index: 2, labels[180]: [ 0.  0.  1.]\n",
      "count: 182, i: 181, class_index: 2, labels[181]: [ 0.  0.  1.]\n",
      "count: 183, i: 182, class_index: 2, labels[182]: [ 0.  0.  1.]\n",
      "count: 184, i: 183, class_index: 2, labels[183]: [ 0.  0.  1.]\n",
      "count: 185, i: 184, class_index: 2, labels[184]: [ 0.  0.  1.]\n",
      "count: 186, i: 185, class_index: 2, labels[185]: [ 0.  0.  1.]\n",
      "count: 187, i: 186, class_index: 2, labels[186]: [ 0.  0.  1.]\n",
      "count: 188, i: 187, class_index: 2, labels[187]: [ 0.  0.  1.]\n",
      "count: 189, i: 188, class_index: 2, labels[188]: [ 0.  0.  1.]\n",
      "count: 190, i: 189, class_index: 2, labels[189]: [ 0.  0.  1.]\n",
      "count: 191, i: 190, class_index: 2, labels[190]: [ 0.  0.  1.]\n",
      "count: 192, i: 191, class_index: 2, labels[191]: [ 0.  0.  1.]\n",
      "count: 193, i: 192, class_index: 2, labels[192]: [ 0.  0.  1.]\n",
      "count: 194, i: 193, class_index: 2, labels[193]: [ 0.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'        \\n\\ndef get_train_feature_generator():\\n    # must return x in the form of (32, 1, 28, 28)\\n    # must return y in the form of (32, 3)\\n    while True:\\n        for i in range()\\n        \\n        \\ny = np.zeros() \\ntrain_generator.classes:\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((194, 3))\n",
    "count = 0\n",
    "for i, class_index in zip(range(0, 194), train_generator.classes):\n",
    "    labels[i][class_index] = 1\n",
    "    count = count + 1\n",
    "    #print(\"count: {}, i: {}, class_index: {}, labels[{}]: {}\".format(count, i, class_index, i, labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.05949762  0.11966778  0.22653553 ...,  0.10000877  0.01944498\n",
      "    0.15126897]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 194 = train_generator.nb_sample\n",
    "# 32 = batch_size\n",
    "\n",
    "\n",
    "def get_train_feature_generator():\n",
    "    # must return x in the form of (32, 1, 28, 28)\n",
    "    # must return y in the form of (32, 3)\n",
    "    while True:\n",
    "        for i in range(int(194/32)):\n",
    "            yield train_features[i*32:(i+1)*32], labels[i*32:(i+1)*32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "0s - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5037 - acc: 0.9688\n",
      "Epoch 3/10\n",
      "0s - loss: 16.1181 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "0s - loss: 16.1181 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "0s - loss: 16.1181 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "0s - loss: 16.1181 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "0s - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "0s - loss: 0.5037 - acc: 0.9688\n",
      "Epoch 9/10\n",
      "0s - loss: 16.1181 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "0s - loss: 16.1181 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bc82376d8>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_generator = get_train_feature_generator()\n",
    "\n",
    "top_model.fit_generator(\n",
    "    generator=train_features_generator,\n",
    "    samples_per_epoch=32,\n",
    "    nb_epoch=10, \n",
    "    #callbacks=callbacks_list,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-7914d73f66c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                         \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "top_model.fit_generator(\n",
    "    generator=train_features_generator,\n",
    "    samples_per_epoch=32,\n",
    "    nb_epoch=10, \n",
    "    callbacks=callbacks_list,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a feature directory to store saved features: ./features/\n",
      "extract features from convolutional model based on data\n",
      "generator: validation_generator\n",
      "batch_size: 32\n",
      "save features to ./features/REALDEAL_DGCarsDataset_ResNet50_validation_features_20170216_23_09_44.npy\n",
      "val_features: (32, 1, 1, 2048), val_labels: (32, 3)\n",
      "32/32 [==============================] - 0s\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "val_features, val_features_path = __extract_features(val_generator, model, batch_size, \"validation\")\n",
    "\n",
    "val_labels = np.zeros((32, 3))\n",
    "\n",
    "for i, class_index in zip(range(0, 32), val_generator.classes):\n",
    "    val_labels[i][class_index] = 1\n",
    "\n",
    "print(\"val_features: {}, val_labels: {}\".format(val_features.shape, val_labels.shape))\n",
    "\n",
    "score = top_model.evaluate(\n",
    "    x=val_features,\n",
    "    y=val_labels,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "print(\"{}: {}\".format(\n",
    "    top_model.metrics_names[1],\n",
    "    score[1]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 1, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-df93e4c7b643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_labels' is not defined"
     ]
    }
   ],
   "source": [
    "val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train entire model with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model                              \n",
    "\n",
    "model = ResNet50(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=Input(\n",
    "                shape=(\n",
    "                    img_height, \n",
    "                    img_width, \n",
    "                    img_dimension\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_model = Model(input=model.input, output=top_model(model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/keras/engine/training.py:1527: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10s - loss: 9.4812 - acc: 0.4118\n",
      "Epoch 2/10\n",
      "1s - loss: 9.0664 - acc: 0.4375\n",
      "Epoch 3/10\n",
      "0s - loss: 12.5923 - acc: 0.2188\n",
      "Epoch 4/10\n",
      "0s - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 5/10\n",
      "0s - loss: 9.5701 - acc: 0.4062\n",
      "Epoch 6/10\n",
      "0s - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 7/10\n",
      "0s - loss: 11.3775 - acc: 0.2941\n",
      "Epoch 8/10\n",
      "0s - loss: 10.5775 - acc: 0.3438\n",
      "Epoch 9/10\n",
      "0s - loss: 11.5849 - acc: 0.2812\n",
      "Epoch 10/10\n",
      "0s - loss: 9.5701 - acc: 0.4062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f39cb10aeb8>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    samples_per_epoch=32,\n",
    "    nb_epoch=10, \n",
    "    #callbacks=callbacks_list,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.3112582793298936\n"
     ]
    }
   ],
   "source": [
    "score = combined_model.evaluate_generator(\n",
    "    generator=val_generator,\n",
    "    val_samples=val_generator.nb_sample\n",
    ")\n",
    "\n",
    "print(\"{}: {}\".format(\n",
    "    combined_model.metrics_names[1],\n",
    "    score[1]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

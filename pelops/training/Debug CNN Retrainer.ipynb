{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f314d9f4cc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "def get_session(gpu_fraction=0.3):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import datetime\n",
    "import enum\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential                              \n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Reshape            \n",
    "from keras.preprocessing import image\n",
    "\n",
    "import pelops.const as const\n",
    "from pelops.datasets.dgcars import DGCarsDataset\n",
    "from pelops.utils import SetType, setup_custom_logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 194\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_dimension = 3\n",
    "\n",
    "train_dir_path = \"./datasets/train/\" \n",
    "val_dir_path = \"./datasets/test/\"\n",
    "train_features_path = None\n",
    "val_features_path = None\n",
    "dataset_type = \"DGCarsDataset\"\n",
    "conv_model_type = \"ResNet50\"\n",
    "conv_model_name = \"ResNet50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1,3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    while True:\\n        xs = []\\n        ys = []\\n        for filename1, filename2 in zip(image_list[0::2], image_list[1::2]):\\n            print(\"filename: {}\".format(filename))\\n            x1 = load_image(filename1)\\n            x2 = load_image(filename2)\\n            x = np.concatenate((x1, x2), axis=0)\\n            xs.append(x)\\n            # if batch_size is greater than one, append more x into xs\\n            print(\"x.shape: {}\".format(x.shape))\\n            y1 = np.zeros((1, num_classes))\\n            y1[0][train_image_class_mapping[filename1]] = 1\\n            y2 = np.zeros((1, num_classes))\\n            y2[0][train_image_class_mapping[filename2]] = 1\\n            y = np.concatenate((y1, y2), axis=0)\\n            ys.append(y)\\n            # if batch_size is greater than one, append more y into ys\\n            print(\"y.shape: {}\".format(y.shape))\\n        yield (np.array(xs).squeeze(), np.array(ys))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    while True:\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for filename1, filename2 in zip(image_list[0::2], image_list[1::2]):\n",
    "            print(\"filename: {}\".format(filename))\n",
    "            x1 = load_image(filename1)\n",
    "            x2 = load_image(filename2)\n",
    "            x = np.concatenate((x1, x2), axis=0)\n",
    "            xs.append(x)\n",
    "            # if batch_size is greater than one, append more x into xs\n",
    "            print(\"x.shape: {}\".format(x.shape))\n",
    "            y1 = np.zeros((1, num_classes))\n",
    "            y1[0][train_image_class_mapping[filename1]] = 1\n",
    "            y2 = np.zeros((1, num_classes))\n",
    "            y2[0][train_image_class_mapping[filename2]] = 1\n",
    "            y = np.concatenate((y1, y2), axis=0)\n",
    "            ys.append(y)\n",
    "            # if batch_size is greater than one, append more y into ys\n",
    "            print(\"y.shape: {}\".format(y.shape))\n",
    "        yield (np.array(xs).squeeze(), np.array(ys))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_image_classes): 3\n",
      "len(image_list): 194\n",
      "count: 1, x.shape: (194, 224, 224, 3), y.shape: (194, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "\n",
    "def load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "    \n",
    "def image_class_generator(train_image_classes_mapping, num_classes, batch_size):\n",
    "    image_list = list(train_image_class_mapping.keys())\n",
    "    print(\"len(image_list): {}\".format(len(image_list)))\n",
    "    \n",
    "    while True:\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for filename in image_list:\n",
    "            #print(\"filename: {}\".format(filename))\n",
    "            x = load_image(filename)\n",
    "            xs.append(x)\n",
    "            # if batch_size is greater than one, append more x into xs\n",
    "            #print(\"x.shape: {}\".format(x.shape))\n",
    "            y = np.zeros(num_classes)\n",
    "            y[train_image_class_mapping[filename]] = 1\n",
    "            ys.append(y)\n",
    "            # if batch_size is greater than one, append more y into ys\n",
    "            #print(\"y.shape: {}\".format(y.shape))\n",
    "        yield (np.array(xs).squeeze(), np.array(ys))\n",
    "    \n",
    "train_image_classes = set()\n",
    "train_image_class_mapping = {}\n",
    "\n",
    "for image_class_filepath in glob.glob(os.path.join(train_dir_path, '*')):\n",
    "    if os.path.isdir(image_class_filepath):\n",
    "        #print(\"image_class_filepath: {}\".format(image_class_filepath))\n",
    "        image_class_num = int(os.path.basename(image_class_filepath)) - 1\n",
    "        #print(\"image_class_num: {}\".format(image_class_num))\n",
    "        train_image_classes.add(image_class_num)\n",
    "        for filename in glob.glob(os.path.join(image_class_filepath, '*')):\n",
    "            #print(\"train_image_class_mapping[{}] = {}\".format(filename, image_class_num))\n",
    "            train_image_class_mapping[filename] = image_class_num\n",
    "\n",
    "nb_classes = len(train_image_classes)\n",
    "print(\"len(train_image_classes): {}\".format(nb_classes))\n",
    "\n",
    "train_generator = image_class_generator(train_image_class_mapping, len(train_image_classes), batch_size)\n",
    "\n",
    "count = 0\n",
    "for i in train_generator:\n",
    "    x, y = i\n",
    "    count = count + 1\n",
    "    print(\"count: {}, x.shape: {}, y.shape: {}\".format(count, x.shape, y.shape))\n",
    "    break\n",
    "\n",
    "    \n",
    "# x.shape == (194, 224, 224, 3)\n",
    "# y.shape == (194, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_image_classes): 3\n"
     ]
    }
   ],
   "source": [
    "val_image_classes = set()\n",
    "val_image_class_mapping = {}\n",
    "\n",
    "for image_class_filepath in glob.glob(os.path.join(val_dir_path, '*')):\n",
    "    if os.path.isdir(image_class_filepath):\n",
    "        #print(\"image_class_filepath: {}\".format(image_class_filepath))\n",
    "        image_class_num = int(os.path.basename(image_class_filepath)) - 1\n",
    "        #print(\"image_class_num: {}\".format(image_class_num))\n",
    "        val_image_classes.add(image_class_num)\n",
    "        for filename in glob.glob(os.path.join(image_class_filepath, '*')):\n",
    "            #print(\"train_image_class_mapping[{}] = {}\".format(filename, image_class_num))\n",
    "            val_image_class_mapping[filename] = image_class_num\n",
    "\n",
    "print(\"len(train_image_classes): {}\".format(len(val_image_classes)))\n",
    "\n",
    "val_generator = image_class_generator(val_image_class_mapping, len(val_image_classes), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=Input(\n",
    "                shape=(\n",
    "                    img_height, \n",
    "                    img_width, \n",
    "                    img_dimension\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __extract_features(generator, model, batch_size, set_type):\n",
    "    feature_dirpath = \"./features/\"\n",
    "    print(\"create a feature directory to store saved features: {}\".format(feature_dirpath))\n",
    "    if not os.path.exists(feature_dirpath):\n",
    "        os.makedirs(feature_dirpath)\n",
    "\n",
    "    print(\"extract features from convolutional model based on data\")\n",
    "    print(\"generator: {}_generator\".format(set_type))\n",
    "    print(\"batch_size: {}\".format(batch_size))\n",
    "    features = model.predict_generator(\n",
    "        generator,\n",
    "        batch_size\n",
    "    )\n",
    "\n",
    "    time_now = datetime.datetime.now().strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "    features_filepath = feature_dirpath + \"TESTING_{}_{}_{}_features_{}.npy\".format(\n",
    "        dataset_type,\n",
    "        conv_model_type,\n",
    "        set_type,\n",
    "        time_now\n",
    "    )\n",
    "    print(\"save features to {}\".format(features_filepath))\n",
    "    np.save(open(features_filepath, \"wb\"), features)\n",
    "\n",
    "    return features, features_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a feature directory to store saved features: ./features/\n",
      "extract features from convolutional model based on data\n",
      "generator: train_generator\n",
      "batch_size: 194\n",
      "save features to ./features/TESTING_DGCarsDataset_ResNet50_train_features_20170214_20_43_52.npy\n"
     ]
    }
   ],
   "source": [
    "train_features, train_features_path = __extract_features(train_generator, model, batch_size, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save features to ./features/TESTING_DGCarsDataset_ResNet50_train_features_20170214_20_12_10.npy\n",
    "#save features to ./features/TESTING_DGCarsDataset_ResNet50_train_features_20170214_20_39_50.npy\n",
    "#save features to ./features/TESTING_DGCarsDataset_ResNet50_train_features_20170214_20_43_52.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feature_path = \"./features/TESTING_DGCarsDataset_ResNet50_train_features_20170214_20_39_50.npy\"\n",
    "train_features = np.load(open(train_feature_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train classifier based on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 1, 1, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1, x.shape: (194, 224, 224, 3), y.shape: (194, 3)\n",
      "(194, 3)\n",
      "(194, 3)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in train_generator:\n",
    "    x, y = i\n",
    "    count = count + 1\n",
    "    print(\"count: {}, x.shape: {}, y.shape: {}\".format(count, x.shape, y.shape))\n",
    "    break\n",
    "\n",
    "print(y.shape)\n",
    "labels = y\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def __create_generator_from_features(features, labels):\n",
    "    for feature, label in zip(features, labels):\n",
    "        yield (feature, label)\n",
    "\n",
    "train_features_generator = __create_generator_from_features(train_features, labels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 2, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 3, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 4, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 5, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 6, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 7, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 8, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 9, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 10, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 11, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 12, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 13, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 14, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 15, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 16, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 17, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 18, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 19, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 20, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 21, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 22, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 23, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 24, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 25, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 26, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 27, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 28, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 29, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 30, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 31, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 32, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 33, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 34, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 35, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 36, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 37, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 38, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 39, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 40, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 41, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 42, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 43, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 44, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 45, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 46, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 47, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 48, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 49, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 50, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 51, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 52, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 53, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 54, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 55, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 56, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 57, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 58, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 59, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 60, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 61, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 62, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 63, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 64, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 65, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 66, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 67, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 68, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 69, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 70, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 71, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 72, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 73, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 74, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 75, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 76, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 77, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 78, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 79, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 80, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 81, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 82, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 83, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 84, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 85, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 86, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 87, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 88, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 89, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 90, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 91, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 92, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 93, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 94, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 95, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 96, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 97, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 98, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 99, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 100, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 101, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 102, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 103, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 104, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 105, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 106, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 107, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 108, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 109, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 110, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 111, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 112, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 113, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 114, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 115, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 116, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 117, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 118, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 119, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 120, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 121, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 122, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 123, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 124, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 125, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 126, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 127, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 128, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 129, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 130, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 131, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 132, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 133, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 134, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 135, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 136, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 137, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 138, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 139, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 140, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 141, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 142, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 143, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 144, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 145, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 146, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 147, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 148, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 149, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 150, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 151, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 152, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 153, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 154, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 155, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 156, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 157, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 158, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 159, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 160, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 161, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 162, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 163, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 164, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 165, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 166, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 167, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 168, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 169, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 170, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 171, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 172, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 173, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 174, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 175, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 176, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 177, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 178, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 179, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 180, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 181, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 182, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 183, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 184, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 185, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 186, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 187, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 188, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 189, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 190, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 191, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 192, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 193, x.shape: (1, 1, 2048), y.shape: (3,)\n",
      "count: 194, x.shape: (1, 1, 2048), y.shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "count = 0\n",
    "for i in train_features_generator:\n",
    "    x, y = i\n",
    "    count = count + 1\n",
    "    print(\"count: {}, x.shape: {}, y.shape: {}\".format(count, x.shape, y.shape))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a checkpoint directory to store saved checkpoints: ./checkpoints/\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dirpath = \"./checkpoints/\"\n",
    "print(\"create a checkpoint directory to store saved checkpoints: {}\".format(checkpoint_dirpath))\n",
    "if not os.path.exists(checkpoint_dirpath):\n",
    "    os.makedirs(checkpoint_dirpath)\n",
    "\n",
    "checkpoint_filepath = \\\n",
    "    checkpoint_dirpath + \\\n",
    "    \"{}_{}_features_\".format(dataset_type, \"classifier\") + \\\n",
    "    \"{epoch:02d}_{val_acc:.2f}.npy\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_filepath, \n",
    "    monitor=\"val_acc\", \n",
    "    save_best_only=True, \n",
    "    mode=\"max\"\n",
    ")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 -> [hidden layer 1026] -> 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_features = model.output_shape[-1] # same as train_features.shape[-1]\n",
    "nb_hidden_layers = int(round(np.mean([nb_features, nb_classes])))\n",
    "print(\"{} -> [hidden layer {}] -> {}\\n\".format(nb_features, nb_hidden_layers, nb_classes))\n",
    "\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Dense(nb_hidden_layers, activation=\"relu\", input_shape=train_features.shape[1:]))\n",
    "top_model.add(Flatten())\n",
    "top_model.add(Dense(nb_classes, activation=\"softmax\")) \n",
    "\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model = Dense(nb_hidden_layers, activation=\"relu\", input_shape=train_features.shape[1:])(top_model)\n",
    "top_model = Flatten()(top_model)\n",
    "top_model = Dense(nb_classes, activation=\"softmax\")(top_model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape: (194, 1, 1, 2048)\n",
      "labels.shape: (194, 3)\n",
      "Epoch 1/10\n",
      "194/194 [==============================] - 0s - loss: 3.4334 - acc: 0.3144     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/10\n",
      "194/194 [==============================] - 0s - loss: 1.5317 - acc: 0.4845     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/10\n",
      "194/194 [==============================] - 0s - loss: 0.8931 - acc: 0.5825     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/10\n",
      "194/194 [==============================] - 0s - loss: 0.7575 - acc: 0.6959     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/10\n",
      "194/194 [==============================] - 0s - loss: 0.6201 - acc: 0.7577     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/10\n",
      "194/194 [==============================] - 0s - loss: 0.5320 - acc: 0.8144     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/10\n",
      "194/194 [==============================] - 0s - loss: 0.4709 - acc: 0.8454     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/10\n",
      "194/194 [==============================] - 0s - loss: 0.4747 - acc: 0.8351     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/10\n",
      "194/194 [==============================] - ETA: 0s - loss: 0.3090 - acc: 0.9500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 0s - loss: 0.3010 - acc: 0.9536     \n",
      "Epoch 10/10\n",
      "194/194 [==============================] - 0s - loss: 0.2913 - acc: 0.9588     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7124dac080>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"train_features.shape: {}\".format(train_features.shape))\n",
    "print(\"labels.shape: {}\".format(y.shape))\n",
    "\n",
    "top_model.fit(\n",
    "    x=train_features,\n",
    "    y=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a feature directory to store saved features: ./features/\n",
      "extract features from convolutional model based on data\n",
      "generator: train_generator\n",
      "batch_size: 194\n",
      "save features to ./features/TESTING_DGCarsDataset_ResNet50_train_features_20170214_23_14_12.npy\n",
      "(194, 1, 1, 2048)\n",
      "(194, 3)\n",
      "194/194 [==============================] - 0s\n",
      "acc: 0.3865979313850403\n"
     ]
    }
   ],
   "source": [
    "val_features, val_features_path = __extract_features(val_generator, model, batch_size, \"train\")\n",
    "\n",
    "print(val_features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "score = top_model.evaluate(\n",
    "    x=val_features,\n",
    "    y=labels,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "print(\"{}: {}\".format(\n",
    "    top_model.metrics_names[1],\n",
    "    score[1]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train entire model with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model                              \n",
    "\n",
    "model = ResNet50(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=Input(\n",
    "                shape=(\n",
    "                    img_height, \n",
    "                    img_width, \n",
    "                    img_dimension\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_model = Model(input=model.input, output=top_model(model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1, x.shape: (194, 224, 224, 3), y.shape: (194, 3)\n",
      "x.shape: (194, 224, 224, 3), y.shape: (194, 3)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in train_generator:\n",
    "    x, y = i\n",
    "    count = count + 1\n",
    "    print(\"count: {}, x.shape: {}, y.shape: {}\".format(count, x.shape, y.shape))\n",
    "    break\n",
    "\n",
    "print(\"x.shape: {}, y.shape: {}\".format(x.shape, y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "194/194 [==============================] - 2s - loss: 1.6541 - acc: 0.4845     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/10\n",
      "194/194 [==============================] - 2s - loss: 0.8336 - acc: 0.6753     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/10\n",
      "194/194 [==============================] - 2s - loss: 0.4715 - acc: 0.8144     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/10\n",
      "194/194 [==============================] - 2s - loss: 0.9739 - acc: 0.7268     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/10\n",
      "194/194 [==============================] - 2s - loss: 0.9672 - acc: 0.7010     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/10\n",
      "194/194 [==============================] - 2s - loss: 0.9624 - acc: 0.6340     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/10\n",
      "194/194 [==============================] - 2s - loss: 0.7284 - acc: 0.7887     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/10\n",
      "194/194 [==============================] - 2s - loss: 0.5870 - acc: 0.7526     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/10\n",
      "194/194 [==============================] - 2s - loss: 0.4786 - acc: 0.8454     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/10\n",
      "194/194 [==============================] - 2s - loss: 0.4721 - acc: 0.8505     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ee4a03400>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit(\n",
    "    x=x,\n",
    "    y=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 3s\n",
      "acc: 0.3865979313850403\n"
     ]
    }
   ],
   "source": [
    "score = combined_model.evaluate(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "print(\"{}: {}\".format(\n",
    "    combined_model.metrics_names[1],\n",
    "    score[1]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
